{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from fastapi import FastAPI, UploadFile, File\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "from PIL import Image\n",
    "import torch\n",
    "import io\n",
    "import numpy as np\n",
    "import uvicorn\n",
    "\n",
    "# ---------------------------\n",
    "# ğŸ”§ FastAPI ê¸°ë³¸ ì„¤ì •\n",
    "# ---------------------------\n",
    "app = FastAPI()\n",
    "\n",
    "# CORS ì„¤ì • â†’ Flutterì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•˜ê²Œ\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\n",
    "        \"https://recycleapp.site\",    # ë„¤ê°€ ë°°í¬í•œ ì•± ë„ë©”ì¸\n",
    "    ],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"POST\"],           # ì˜ˆì¸¡ë§Œ í•  ê±°ë‹ˆê¹Œ POSTë§Œ\n",
    "    allow_headers=[\"Content-Type\"],   # JSON ìš”ì²­ë§Œ í—ˆìš©\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# ğŸ”§ ëª¨ë¸ ë¡œë“œ (1íšŒë§Œ ìˆ˜í–‰)\n",
    "# ---------------------------\n",
    "MODEL_PATH = \"C:/Users/USER/Desktop/Recycle_Segmentation/best_model\"  \n",
    "\n",
    "print(\"ğŸš€ ëª¨ë¸ ë¡œë“œ ì¤‘...\")\n",
    "model = AutoModelForSemanticSegmentation.from_pretrained(MODEL_PATH)\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_PATH)\n",
    "model.eval()  # í‰ê°€ ëª¨ë“œ\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "\n",
    "# ---------------------------\n",
    "# ğŸ” ì˜ˆì¸¡ í•¨ìˆ˜\n",
    "# ---------------------------\n",
    "def predict_image(image_bytes):\n",
    "    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # ëª¨ë¸ ì¶”ë¡ \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # ê²°ê³¼: í´ë˜ìŠ¤ë³„ softmax â†’ ê°€ì¥ í™•ë¥  ë†’ì€ í´ë˜ìŠ¤ ì¶”ì¶œ\n",
    "    preds = torch.argmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
    "\n",
    "    # numpy ë°°ì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì„œ ë°˜í™˜\n",
    "    return preds.tolist()\n",
    "\n",
    "# ---------------------------\n",
    "# ğŸ“¤ API ì—”ë“œí¬ì¸íŠ¸\n",
    "# ---------------------------\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    image_bytes = await file.read()\n",
    "    \n",
    "    # ì˜ˆì¸¡ ì‹¤í–‰\n",
    "    prediction = predict_image(image_bytes)\n",
    "\n",
    "    # ê²°ê³¼ ë°˜í™˜\n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"prediction\": prediction  # 2D ë¦¬ìŠ¤íŠ¸ (segmentation mask)\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# ğŸ”§ ë¡œì»¬ ì‹¤í–‰\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=8000, reload=True)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
