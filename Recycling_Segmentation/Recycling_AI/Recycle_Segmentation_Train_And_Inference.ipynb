{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗂️ 데이터 정리 시작...\n",
      "📁 train 폴더에서 찾은 이미지: 930개\n",
      "📁 train 폴더에서 찾은 마스크: 930개\n",
      "✅ 데이터 정리 완료!\n",
      "   📁 이미지: 930개 → datasets/images/\n",
      "   📁 마스크: 930개 → datasets/masks/\n",
      "🔧 사용 디바이스: cuda\n",
      "🚀 깔끔한 Recycle Segmentation 파이프라인 시작!\n",
      "================================================================================\n",
      "\n",
      "📊 STEP 1: 데이터 전처리 시작\n",
      "\n",
      "============================================================\n",
      "📊 STEP 1: datasets 폴더 데이터 매칭 시작\n",
      "📁 JPG 이미지 파일 개수: 930개\n",
      "📁 PNG 마스크 파일 개수: 930개\n",
      "✅ 숫자 기반 매칭 성공: 930개\n",
      "🔍 매칭된 이미지-마스크 쌍: 930개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "데이터 매칭: 100%|██████████| 930/930 [00:02<00:00, 423.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 최종 데이터 개수: 930개\n",
      "✅ 전처리 완료: 930개 데이터\n",
      "\n",
      "🔧 STEP 2: 클래스 가중치 계산\n",
      "\n",
      "📊 클래스 가중치 계산 중...\n",
      "🎯 클래스별 가중치:\n",
      "   background: 0.195 (픽셀 수: 178,471,959)\n",
      "   can: 5.586 (픽셀 수: 6,234,788)\n",
      "   glass: 5.579 (픽셀 수: 6,242,213)\n",
      "   paper: 4.862 (픽셀 수: 7,163,569)\n",
      "   plastic: 2.850 (픽셀 수: 12,220,847)\n",
      "   styrofoam: 3.296 (픽셀 수: 10,565,234)\n",
      "   vinyl: 1.521 (픽셀 수: 22,895,310)\n",
      "✅ 클래스 가중치 계산 완료\n",
      "\n",
      "🤖 모델 및 프로세서 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of MobileViTForSemanticSegmentation were not initialized from the model checkpoint at apple/deeplabv3-mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- segmentation_head.classifier.convolution.weight: found shape torch.Size([21, 256, 1, 1]) in the checkpoint and torch.Size([7, 256, 1, 1]) in the model instantiated\n",
      "- segmentation_head.classifier.convolution.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모델 로딩 완료\n",
      "\n",
      "📊 Train/Val 데이터 분할 중...\n",
      "📊 데이터 분할 완료: Train 744개, Val 186개\n",
      "🔍 필터링 없는 데이터셋 생성 중...\n",
      "📊 입력 데이터 개수: 744개\n",
      "📊 전체 데이터셋 크기: 744개\n",
      "✅ 최종 데이터셋 크기: 744개\n",
      "🔍 필터링 없는 데이터셋 생성 중...\n",
      "📊 입력 데이터 개수: 186개\n",
      "📊 전체 데이터셋 크기: 186개\n",
      "✅ 최종 데이터셋 크기: 186개\n",
      "✅ DataLoader 생성 완료: Train batches 46, Val batches 12\n",
      "\n",
      "🚀 STEP 3: 모델 학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:483: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:517: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  ▶  Train Loss: 1.0833  |  Val Loss: 1.0572  |  Dice: 0.4425  |  IoU: 0.2943  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.4425 저장 완료\n",
      "Epoch 2/200  ▶  Train Loss: 1.0428  |  Val Loss: 1.0124  |  Dice: 0.6619  |  IoU: 0.5223  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.6619 저장 완료\n",
      "Epoch 3/200  ▶  Train Loss: 0.9948  |  Val Loss: 0.9483  |  Dice: 0.8392  |  IoU: 0.7391  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.8392 저장 완료\n",
      "Epoch 4/200  ▶  Train Loss: 0.9270  |  Val Loss: 0.8712  |  Dice: 0.8935  |  IoU: 0.8166  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.8935 저장 완료\n",
      "Epoch 5/200  ▶  Train Loss: 0.8556  |  Val Loss: 0.8046  |  Dice: 0.9091  |  IoU: 0.8395  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9091 저장 완료\n",
      "Epoch 6/200  ▶  Train Loss: 0.7926  |  Val Loss: 0.7363  |  Dice: 0.9326  |  IoU: 0.8772  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9326 저장 완료\n",
      "Epoch 7/200  ▶  Train Loss: 0.7384  |  Val Loss: 0.6944  |  Dice: 0.9397  |  IoU: 0.8893  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9397 저장 완료\n",
      "Epoch 8/200  ▶  Train Loss: 0.6970  |  Val Loss: 0.6613  |  Dice: 0.9549  |  IoU: 0.9154  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9549 저장 완료\n",
      "Epoch 9/200  ▶  Train Loss: 0.6692  |  Val Loss: 0.6260  |  Dice: 0.9642  |  IoU: 0.9321  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9642 저장 완료\n",
      "Epoch 10/200  ▶  Train Loss: 0.6390  |  Val Loss: 0.6049  |  Dice: 0.9681  |  IoU: 0.9393  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9681 저장 완료\n",
      "Epoch 11/200  ▶  Train Loss: 0.6171  |  Val Loss: 0.5823  |  Dice: 0.9727  |  IoU: 0.9478  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9727 저장 완료\n",
      "Epoch 12/200  ▶  Train Loss: 0.6005  |  Val Loss: 0.5703  |  Dice: 0.9814  |  IoU: 0.9638  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9814 저장 완료\n",
      "Epoch 13/200  ▶  Train Loss: 0.5844  |  Val Loss: 0.5570  |  Dice: 0.9819  |  IoU: 0.9647  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9819 저장 완료\n",
      "Epoch 14/200  ▶  Train Loss: 0.5674  |  Val Loss: 0.5458  |  Dice: 0.9824  |  IoU: 0.9659  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9824 저장 완료\n",
      "Epoch 15/200  ▶  Train Loss: 0.5531  |  Val Loss: 0.5327  |  Dice: 0.9839  |  IoU: 0.9687  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9839 저장 완료\n",
      "Epoch 16/200  ▶  Train Loss: 0.5407  |  Val Loss: 0.5215  |  Dice: 0.9848  |  IoU: 0.9704  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9848 저장 완료\n",
      "Epoch 17/200  ▶  Train Loss: 0.5252  |  Val Loss: 0.5124  |  Dice: 0.9855  |  IoU: 0.9717  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9855 저장 완료\n",
      "Epoch 18/200  ▶  Train Loss: 0.5175  |  Val Loss: 0.5030  |  Dice: 0.9862  |  IoU: 0.9730  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9862 저장 완료\n",
      "Epoch 19/200  ▶  Train Loss: 0.5071  |  Val Loss: 0.4991  |  Dice: 0.9808  |  IoU: 0.9629  |  LR: 1.00e-04\n",
      "Epoch 20/200  ▶  Train Loss: 0.5000  |  Val Loss: 0.4898  |  Dice: 0.9859  |  IoU: 0.9725  |  LR: 1.00e-04\n",
      "Epoch 21/200  ▶  Train Loss: 0.4922  |  Val Loss: 0.4860  |  Dice: 0.9856  |  IoU: 0.9719  |  LR: 1.00e-04\n",
      "Epoch 22/200  ▶  Train Loss: 0.4833  |  Val Loss: 0.4768  |  Dice: 0.9866  |  IoU: 0.9737  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9866 저장 완료\n",
      "Epoch 23/200  ▶  Train Loss: 0.4763  |  Val Loss: 0.4719  |  Dice: 0.9872  |  IoU: 0.9750  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9872 저장 완료\n",
      "Epoch 24/200  ▶  Train Loss: 0.4726  |  Val Loss: 0.4677  |  Dice: 0.9877  |  IoU: 0.9758  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9877 저장 완료\n",
      "Epoch 25/200  ▶  Train Loss: 0.4646  |  Val Loss: 0.4646  |  Dice: 0.9860  |  IoU: 0.9727  |  LR: 1.00e-04\n",
      "Epoch 26/200  ▶  Train Loss: 0.4623  |  Val Loss: 0.4613  |  Dice: 0.9865  |  IoU: 0.9737  |  LR: 1.00e-04\n",
      "Epoch 27/200  ▶  Train Loss: 0.4569  |  Val Loss: 0.4575  |  Dice: 0.9869  |  IoU: 0.9744  |  LR: 1.00e-04\n",
      "Epoch 28/200  ▶  Train Loss: 0.4536  |  Val Loss: 0.4552  |  Dice: 0.9873  |  IoU: 0.9751  |  LR: 1.00e-04\n",
      "Epoch 29/200  ▶  Train Loss: 0.4515  |  Val Loss: 0.4520  |  Dice: 0.9882  |  IoU: 0.9768  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9882 저장 완료\n",
      "Epoch 30/200  ▶  Train Loss: 0.4501  |  Val Loss: 0.4499  |  Dice: 0.9877  |  IoU: 0.9759  |  LR: 1.00e-04\n",
      "Epoch 31/200  ▶  Train Loss: 0.4484  |  Val Loss: 0.4484  |  Dice: 0.9875  |  IoU: 0.9755  |  LR: 1.00e-04\n",
      "Epoch 32/200  ▶  Train Loss: 0.4494  |  Val Loss: 0.4473  |  Dice: 0.9880  |  IoU: 0.9764  |  LR: 1.00e-04\n",
      "Epoch 33/200  ▶  Train Loss: 0.4449  |  Val Loss: 0.4457  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9886 저장 완료\n",
      "Epoch 34/200  ▶  Train Loss: 0.4408  |  Val Loss: 0.4450  |  Dice: 0.9887  |  IoU: 0.9777  |  LR: 1.00e-04\n",
      "✅ New Best! Dice 0.9887 저장 완료\n",
      "Epoch 35/200  ▶  Train Loss: 0.4387  |  Val Loss: 0.4461  |  Dice: 0.9864  |  IoU: 0.9734  |  LR: 1.00e-04\n",
      "Epoch 36/200  ▶  Train Loss: 0.4369  |  Val Loss: 0.4428  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 37/200  ▶  Train Loss: 0.4362  |  Val Loss: 0.4413  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 7.00e-05\n",
      "✅ New Best! Dice 0.9890 저장 완료\n",
      "Epoch 38/200  ▶  Train Loss: 0.4348  |  Val Loss: 0.4411  |  Dice: 0.9888  |  IoU: 0.9780  |  LR: 7.00e-05\n",
      "Epoch 39/200  ▶  Train Loss: 0.4345  |  Val Loss: 0.4400  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 40/200  ▶  Train Loss: 0.4339  |  Val Loss: 0.4398  |  Dice: 0.9885  |  IoU: 0.9774  |  LR: 7.00e-05\n",
      "Epoch 41/200  ▶  Train Loss: 0.4327  |  Val Loss: 0.4396  |  Dice: 0.9884  |  IoU: 0.9772  |  LR: 7.00e-05\n",
      "Epoch 42/200  ▶  Train Loss: 0.4320  |  Val Loss: 0.4393  |  Dice: 0.9889  |  IoU: 0.9782  |  LR: 7.00e-05\n",
      "Epoch 43/200  ▶  Train Loss: 0.4324  |  Val Loss: 0.4385  |  Dice: 0.9885  |  IoU: 0.9773  |  LR: 7.00e-05\n",
      "Epoch 44/200  ▶  Train Loss: 0.4313  |  Val Loss: 0.4380  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 45/200  ▶  Train Loss: 0.4308  |  Val Loss: 0.4376  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 7.00e-05\n",
      "✅ New Best! Dice 0.9891 저장 완료\n",
      "Epoch 46/200  ▶  Train Loss: 0.4294  |  Val Loss: 0.4378  |  Dice: 0.9885  |  IoU: 0.9774  |  LR: 7.00e-05\n",
      "Epoch 47/200  ▶  Train Loss: 0.4298  |  Val Loss: 0.4364  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 7.00e-05\n",
      "Epoch 48/200  ▶  Train Loss: 0.4283  |  Val Loss: 0.4360  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 7.00e-05\n",
      "✅ New Best! Dice 0.9894 저장 완료\n",
      "Epoch 49/200  ▶  Train Loss: 0.4272  |  Val Loss: 0.4356  |  Dice: 0.9892  |  IoU: 0.9787  |  LR: 4.90e-05\n",
      "Epoch 50/200  ▶  Train Loss: 0.4268  |  Val Loss: 0.4357  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 4.90e-05\n",
      "✅ New Best! Dice 0.9895 저장 완료\n",
      "Epoch 51/200  ▶  Train Loss: 0.4278  |  Val Loss: 0.4351  |  Dice: 0.9897  |  IoU: 0.9797  |  LR: 4.90e-05\n",
      "✅ New Best! Dice 0.9897 저장 완료\n",
      "Epoch 52/200  ▶  Train Loss: 0.4267  |  Val Loss: 0.4351  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 4.90e-05\n",
      "Epoch 53/200  ▶  Train Loss: 0.4263  |  Val Loss: 0.4350  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 4.90e-05\n",
      "Epoch 54/200  ▶  Train Loss: 0.4258  |  Val Loss: 0.4343  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 4.90e-05\n",
      "Epoch 55/200  ▶  Train Loss: 0.4253  |  Val Loss: 0.4344  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 4.90e-05\n",
      "Epoch 56/200  ▶  Train Loss: 0.4251  |  Val Loss: 0.4344  |  Dice: 0.9889  |  IoU: 0.9781  |  LR: 4.90e-05\n",
      "Epoch 57/200  ▶  Train Loss: 0.4249  |  Val Loss: 0.4344  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 4.90e-05\n",
      "Epoch 58/200  ▶  Train Loss: 0.4240  |  Val Loss: 0.4336  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 4.90e-05\n",
      "Epoch 59/200  ▶  Train Loss: 0.4242  |  Val Loss: 0.4330  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 4.90e-05\n",
      "Epoch 60/200  ▶  Train Loss: 0.4238  |  Val Loss: 0.4341  |  Dice: 0.9887  |  IoU: 0.9778  |  LR: 4.90e-05\n",
      "Epoch 61/200  ▶  Train Loss: 0.4243  |  Val Loss: 0.4331  |  Dice: 0.9887  |  IoU: 0.9777  |  LR: 4.90e-05\n",
      "Epoch 62/200  ▶  Train Loss: 0.4234  |  Val Loss: 0.4327  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 63/200  ▶  Train Loss: 0.4232  |  Val Loss: 0.4327  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 3.43e-05\n",
      "Epoch 64/200  ▶  Train Loss: 0.4229  |  Val Loss: 0.4323  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 65/200  ▶  Train Loss: 0.4226  |  Val Loss: 0.4326  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 66/200  ▶  Train Loss: 0.4228  |  Val Loss: 0.4327  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 67/200  ▶  Train Loss: 0.4225  |  Val Loss: 0.4318  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 3.43e-05\n",
      "Epoch 68/200  ▶  Train Loss: 0.4219  |  Val Loss: 0.4320  |  Dice: 0.9898  |  IoU: 0.9799  |  LR: 3.43e-05\n",
      "✅ New Best! Dice 0.9898 저장 완료\n",
      "Epoch 69/200  ▶  Train Loss: 0.4215  |  Val Loss: 0.4322  |  Dice: 0.9892  |  IoU: 0.9787  |  LR: 3.43e-05\n",
      "Epoch 70/200  ▶  Train Loss: 0.4217  |  Val Loss: 0.4318  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 71/200  ▶  Train Loss: 0.4216  |  Val Loss: 0.4321  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 3.43e-05\n",
      "Epoch 72/200  ▶  Train Loss: 0.4211  |  Val Loss: 0.4313  |  Dice: 0.9899  |  IoU: 0.9801  |  LR: 3.43e-05\n",
      "✅ New Best! Dice 0.9899 저장 완료\n",
      "Epoch 73/200  ▶  Train Loss: 0.4212  |  Val Loss: 0.4312  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 74/200  ▶  Train Loss: 0.4211  |  Val Loss: 0.4312  |  Dice: 0.9896  |  IoU: 0.9796  |  LR: 3.43e-05\n",
      "Epoch 75/200  ▶  Train Loss: 0.4208  |  Val Loss: 0.4311  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 2.40e-05\n",
      "Epoch 76/200  ▶  Train Loss: 0.4207  |  Val Loss: 0.4314  |  Dice: 0.9893  |  IoU: 0.9790  |  LR: 2.40e-05\n",
      "Epoch 77/200  ▶  Train Loss: 0.4201  |  Val Loss: 0.4311  |  Dice: 0.9889  |  IoU: 0.9782  |  LR: 2.40e-05\n",
      "Epoch 78/200  ▶  Train Loss: 0.4207  |  Val Loss: 0.4311  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 2.40e-05\n",
      "Epoch 79/200  ▶  Train Loss: 0.4201  |  Val Loss: 0.4309  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 2.40e-05\n",
      "Epoch 80/200  ▶  Train Loss: 0.4202  |  Val Loss: 0.4314  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 2.40e-05\n",
      "Epoch 81/200  ▶  Train Loss: 0.4200  |  Val Loss: 0.4310  |  Dice: 0.9896  |  IoU: 0.9795  |  LR: 2.40e-05\n",
      "Epoch 82/200  ▶  Train Loss: 0.4208  |  Val Loss: 0.4308  |  Dice: 0.9898  |  IoU: 0.9799  |  LR: 2.40e-05\n",
      "Epoch 83/200  ▶  Train Loss: 0.4199  |  Val Loss: 0.4304  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 2.40e-05\n",
      "Epoch 84/200  ▶  Train Loss: 0.4201  |  Val Loss: 0.4307  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 2.40e-05\n",
      "Epoch 85/200  ▶  Train Loss: 0.4196  |  Val Loss: 0.4311  |  Dice: 0.9887  |  IoU: 0.9778  |  LR: 2.40e-05\n",
      "Epoch 86/200  ▶  Train Loss: 0.4191  |  Val Loss: 0.4307  |  Dice: 0.9892  |  IoU: 0.9788  |  LR: 2.40e-05\n",
      "Epoch 87/200  ▶  Train Loss: 0.4198  |  Val Loss: 0.4307  |  Dice: 0.9889  |  IoU: 0.9780  |  LR: 2.40e-05\n",
      "Epoch 88/200  ▶  Train Loss: 0.4194  |  Val Loss: 0.4306  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 89/200  ▶  Train Loss: 0.4195  |  Val Loss: 0.4307  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 1.68e-05\n",
      "Epoch 90/200  ▶  Train Loss: 0.4190  |  Val Loss: 0.4305  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 1.68e-05\n",
      "Epoch 91/200  ▶  Train Loss: 0.4188  |  Val Loss: 0.4304  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 92/200  ▶  Train Loss: 0.4188  |  Val Loss: 0.4302  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 1.68e-05\n",
      "Epoch 93/200  ▶  Train Loss: 0.4189  |  Val Loss: 0.4300  |  Dice: 0.9896  |  IoU: 0.9794  |  LR: 1.68e-05\n",
      "Epoch 94/200  ▶  Train Loss: 0.4185  |  Val Loss: 0.4302  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 1.68e-05\n",
      "Epoch 95/200  ▶  Train Loss: 0.4181  |  Val Loss: 0.4300  |  Dice: 0.9897  |  IoU: 0.9796  |  LR: 1.68e-05\n",
      "Epoch 96/200  ▶  Train Loss: 0.4186  |  Val Loss: 0.4302  |  Dice: 0.9893  |  IoU: 0.9790  |  LR: 1.68e-05\n",
      "Epoch 97/200  ▶  Train Loss: 0.4183  |  Val Loss: 0.4301  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 1.68e-05\n",
      "Epoch 98/200  ▶  Train Loss: 0.4181  |  Val Loss: 0.4298  |  Dice: 0.9898  |  IoU: 0.9798  |  LR: 1.68e-05\n",
      "Epoch 99/200  ▶  Train Loss: 0.4180  |  Val Loss: 0.4301  |  Dice: 0.9896  |  IoU: 0.9796  |  LR: 1.68e-05\n",
      "Epoch 100/200  ▶  Train Loss: 0.4179  |  Val Loss: 0.4299  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 101/200  ▶  Train Loss: 0.4176  |  Val Loss: 0.4299  |  Dice: 0.9896  |  IoU: 0.9795  |  LR: 1.18e-05\n",
      "Epoch 102/200  ▶  Train Loss: 0.4179  |  Val Loss: 0.4301  |  Dice: 0.9893  |  IoU: 0.9788  |  LR: 1.18e-05\n",
      "\n",
      "🛑 Early stopping at epoch 102\n",
      "\n",
      "📥 Best 모델 로딩 중: C:/Users/USER/Desktop/Reco_Notebook\\results\\best_model\n",
      "✅ Best 모델 로딩 완료!\n",
      "\n",
      "📊 최종 성능 평가 중...\n",
      "\n",
      "🗂️ STEP 4: 깔끔한 결과 저장\n",
      "🗂️ 깔끔한 결과 저장 시작...\n",
      "✅ 1. Best Model 확인됨: C:/Users/USER/Desktop/Reco_Notebook\\results\\best_model\n",
      "🎨 2. 모든 예측 결과 시각화 저장 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "시각화 저장: 100%|██████████| 12/12 [02:08<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 2. 시각화 완료: 186개 이미지 → C:/Users/USER/Desktop/Reco_Notebook\\results\\visualizations\n",
      "✅ 3. 성능 결과 저장: C:/Users/USER/Desktop/Reco_Notebook\\results\\performance\n",
      "\n",
      "🎉 깔끔한 저장 완료!\n",
      "📁 저장 위치: C:/Users/USER/Desktop/Reco_Notebook\\results\n",
      "📊 구조:\n",
      "  ├── best_model/        (학습된 모델)\n",
      "  ├── visualizations/    (186개 예측 시각화)\n",
      "  └── performance/       (성능 그래프 + 리포트)\n",
      "\n",
      "🎉 완료! 모든 결과가 저장되었습니다:\n",
      "📁 C:/Users/USER/Desktop/Reco_Notebook\\results\n",
      "📊 최종 성능: Dice 0.9899, IoU 0.9801\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# 🚀 완전한 Recycle Segmentation 파이프라인\n",
    "# ===============================================================================\n",
    "\n",
    "# PyTorch 관련 임포트\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Transformers 관련 임포트\n",
    "from transformers import AutoImageProcessor, AutoModelForSemanticSegmentation\n",
    "\n",
    "# 이미지 처리 관련 임포트\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# 시스템 및 유틸리티 임포트\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "# 진행상황 및 데이터 처리 관련 임포트\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import albumentations as A\n",
    "from itertools import cycle\n",
    "\n",
    "# ===============================================================================\n",
    "# 📋 STEP 0: 데이터 정리 및 기본 설정\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"🗂️ 데이터 정리 시작...\")\n",
    "\n",
    "# 데이터 정리: train 폴더에서 datasets 폴더로 이동\n",
    "base_dir = \"C:/Users/USER/Desktop/Reco_Notebook\"\n",
    "os.makedirs(os.path.join(base_dir, \"datasets\"), exist_ok=True)\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "train_imgs = glob(os.path.join(train_dir, \"*.jpg\"))\n",
    "train_masks = glob(os.path.join(train_dir, \"*.png\"))\n",
    "\n",
    "print(f\"📁 train 폴더에서 찾은 이미지: {len(train_imgs)}개\")\n",
    "print(f\"📁 train 폴더에서 찾은 마스크: {len(train_masks)}개\")\n",
    "\n",
    "# 이미지 복사\n",
    "for train_img in train_imgs:\n",
    "    image_dir = os.path.join(base_dir, \"datasets\", \"images\", os.path.basename(train_img))\n",
    "    os.makedirs(os.path.dirname(image_dir), exist_ok=True)\n",
    "    shutil.copy(train_img, image_dir)\n",
    "\n",
    "# 마스크 복사\n",
    "for train_mask in train_masks:\n",
    "    mask_dir = os.path.join(base_dir, \"datasets\", \"masks\", os.path.basename(train_mask))\n",
    "    os.makedirs(os.path.dirname(mask_dir), exist_ok=True)\n",
    "    shutil.copy(train_mask, mask_dir)\n",
    "\n",
    "print(f\"✅ 데이터 정리 완료!\")\n",
    "print(f\"   📁 이미지: {len(train_imgs)}개 → datasets/images/\")\n",
    "print(f\"   📁 마스크: {len(train_masks)}개 → datasets/masks/\")\n",
    "\n",
    "# 클래스 정의: 7개 클래스 (background 포함)\n",
    "class_names = [\n",
    "    \"background\", \"can\", \"glass\",\n",
    "    \"paper\", \"plastic\", \"styrofoam\", \"vinyl\"\n",
    "]\n",
    "\n",
    "# 클래스명 ↔ ID 매핑\n",
    "label2id = {name: i for i, name in enumerate(class_names)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# 시각화용 색상 (배경은 투명 처리)\n",
    "class_colors_bright = [\n",
    "    None,             # background - 투명 (원본 이미지 배경 보임)\n",
    "    (0, 255, 255),    # can - 밝은 청록색 (Cyan)\n",
    "    (255, 255, 0),    # glass - 밝은 노란색\n",
    "    (128, 255, 0),    # paper - 연두색\n",
    "    (255, 0, 0),      # plastic - 밝은 빨간색\n",
    "    (0, 128, 255),    # styrofoam - 밝은 파란색\n",
    "    (255, 0, 128)     # vinyl - 밝은 분홍색\n",
    "]\n",
    "\n",
    "# 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🔧 사용 디바이스: {device}\")\n",
    "\n",
    "# 데이터 경로 설정\n",
    "image_dir = os.path.join(base_dir, \"datasets\", \"images\")\n",
    "mask_dir = os.path.join(base_dir, \"datasets\", \"masks\")\n",
    "\n",
    "# ===============================================================================\n",
    "# 🔍 STEP 1: 이미지-마스크 파일 매칭 및 데이터셋\n",
    "# ===============================================================================\n",
    "\n",
    "def preprocess_datasets():\n",
    "    \"\"\"datasets 폴더의 images(.jpg)와 masks(.png)를 매칭하고 클래스별 픽셀 수 계산\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📊 STEP 1: datasets 폴더 데이터 매칭 시작\")\n",
    "\n",
    "    def get_base_name(filename):\n",
    "        \"\"\"파일명에서 숫자 기반 키 생성 (숫자만 추출)\"\"\"\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return '_'.join(numbers) if numbers else filename\n",
    "\n",
    "    def find_matching_files():\n",
    "        # 숫자 기반 매칭 방법 (930개 모두 성공!)\n",
    "        image_list = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]\n",
    "        mask_list = [f for f in os.listdir(mask_dir) if f.lower().endswith('.png')]\n",
    "        \n",
    "        print(f\"📁 JPG 이미지 파일 개수: {len(image_list)}개\")\n",
    "        print(f\"📁 PNG 마스크 파일 개수: {len(mask_list)}개\")\n",
    "        \n",
    "        def get_numeric_key(filename):\n",
    "            \"\"\"파일명에서 숫자만 추출해서 키 생성\"\"\"\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', filename)\n",
    "            return '_'.join(numbers) if numbers else filename\n",
    "        \n",
    "        # 숫자 기반으로 매칭\n",
    "        image_dict = {get_numeric_key(f): f for f in image_list}\n",
    "        mask_dict = {get_numeric_key(f): f for f in mask_list}\n",
    "        \n",
    "        matched_pairs = []\n",
    "        for base_key in image_dict:\n",
    "            if base_key in mask_dict:\n",
    "                matched_pairs.append({\n",
    "                    'base_name': base_key, \n",
    "                    'image_file': image_dict[base_key], \n",
    "                    'mask_file': mask_dict[base_key]\n",
    "                })\n",
    "        \n",
    "        # 매칭 결과 확인\n",
    "        image_only = set(image_dict.keys()) - set(mask_dict.keys())\n",
    "        mask_only = set(mask_dict.keys()) - set(image_dict.keys())\n",
    "        \n",
    "        if image_only:\n",
    "            print(f\"⚠️ 매칭되지 않은 이미지: {len(image_only)}개\")\n",
    "            if len(image_only) <= 3:\n",
    "                for key in list(image_only):\n",
    "                    print(f\"   - {image_dict[key]}\")\n",
    "        \n",
    "        if mask_only:\n",
    "            print(f\"⚠️ 매칭되지 않은 마스크: {len(mask_only)}개\")\n",
    "            if len(mask_only) <= 3:\n",
    "                for key in list(mask_only):\n",
    "                    print(f\"   - {mask_dict[key]}\")\n",
    "        \n",
    "        print(f\"✅ 숫자 기반 매칭 성공: {len(matched_pairs)}개\")\n",
    "        return matched_pairs\n",
    "\n",
    "    final_data_list = []\n",
    "    pixel_counter = Counter()\n",
    "    matched_pairs = find_matching_files()\n",
    "\n",
    "    print(f\"🔍 매칭된 이미지-마스크 쌍: {len(matched_pairs)}개\")\n",
    "\n",
    "    for pair in tqdm(matched_pairs, desc=\"데이터 매칭\"):\n",
    "        img_path = os.path.join(image_dir, pair['image_file'])\n",
    "        mask_path = os.path.join(mask_dir, pair['mask_file'])\n",
    "\n",
    "        if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mask_array = np.array(Image.open(mask_path))\n",
    "            unique_classes = np.unique(mask_array)\n",
    "            for class_id in unique_classes:\n",
    "                if class_id in label2id.values():\n",
    "                    pixel_counter[class_id] += (mask_array == class_id).sum()\n",
    "\n",
    "            final_data_list.append({\n",
    "                \"image\": img_path,\n",
    "                \"label\": mask_path,\n",
    "                \"class_ids\": unique_classes.tolist(),\n",
    "                \"base_name\": pair['base_name']\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 마스크 로딩 오류: {pair['base_name']} - {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"✅ 최종 데이터 개수: {len(final_data_list)}개\")\n",
    "    return final_data_list, pixel_counter\n",
    "\n",
    "def create_basic_transforms(input_size=512):\n",
    "    return A.Compose([A.Resize(input_size, input_size)])\n",
    "\n",
    "class ImprovedSegDataset(Dataset):\n",
    "    def __init__(self, items, processor, input_size=512):\n",
    "        self.items = items\n",
    "        self.processor = processor\n",
    "        self.input_size = input_size\n",
    "        self.transform = create_basic_transforms(input_size)\n",
    "        self.max_class_id = max(label2id.values())\n",
    "        self.valid_items = items\n",
    "        print(f\"📊 전체 데이터셋 크기: {len(self.valid_items)}개\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.valid_items):\n",
    "            idx = idx % len(self.valid_items)\n",
    "\n",
    "        rec = self.valid_items[idx]\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(rec['image'])\n",
    "            if image is None:\n",
    "                raise ValueError(f\"이미지 로드 실패: {rec['image']}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask = cv2.imread(rec['label'], cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"마스크 로드 실패: {rec['label']}\")\n",
    "\n",
    "            if image.shape[:2] != mask.shape[:2]:\n",
    "                h, w = min(image.shape[0], mask.shape[0]), min(image.shape[1], mask.shape[1])\n",
    "                image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            mask = np.clip(mask, 0, self.max_class_id)\n",
    "\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    transformed = self.transform(image=image, mask=mask)\n",
    "                    image, mask = transformed['image'], transformed['mask']\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Transform 오류: {e}\")\n",
    "\n",
    "            try:\n",
    "                proc = self.processor(images=image, return_tensors=\"pt\")\n",
    "                pixel_values = proc[\"pixel_values\"].squeeze(0)\n",
    "            except Exception as e:\n",
    "                image_tensor = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
    "                pixel_values = image_tensor\n",
    "\n",
    "            labels = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "            return {\n",
    "                \"pixel_values\": pixel_values,\n",
    "                \"labels\": labels,\n",
    "                \"filename\": os.path.basename(rec['image']),\n",
    "                \"original_image_path\": rec['image']\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 데이터 로딩 오류: {rec['image']} - {str(e)}\")\n",
    "            if idx == 0:\n",
    "                return self._get_dummy_data()\n",
    "            else:\n",
    "                return self.__getitem__(0)\n",
    "\n",
    "    def _get_dummy_data(self):\n",
    "        dummy_image = torch.zeros(3, self.input_size, self.input_size, dtype=torch.float32)\n",
    "        dummy_mask = torch.zeros(self.input_size, self.input_size, dtype=torch.long)\n",
    "        return {\n",
    "            \"pixel_values\": dummy_image,\n",
    "            \"labels\": dummy_mask,\n",
    "            \"filename\": \"dummy.jpg\",\n",
    "            \"original_image_path\": \"dummy_path\"\n",
    "        }\n",
    "\n",
    "def create_clean_dataset(items, processor, input_size=512):\n",
    "    print(f\"🔍 필터링 없는 데이터셋 생성 중...\")\n",
    "    print(f\"📊 입력 데이터 개수: {len(items)}개\")\n",
    "    dataset = ImprovedSegDataset(items, processor, input_size)\n",
    "    print(f\"✅ 최종 데이터셋 크기: {len(dataset)}개\")\n",
    "    return dataset\n",
    "\n",
    "# ===============================================================================\n",
    "# 🚀 STEP 2: Loss 함수 및 학습 시스템\n",
    "# ===============================================================================\n",
    "\n",
    "class CombinedBoundaryLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None, dice_weight=0.5, ce_weight=0.3, boundary_weight=0.2, smooth=1e-7):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.boundary_weight = boundary_weight\n",
    "        self.smooth = smooth\n",
    "\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('sobel_x', sobel_x)\n",
    "        self.register_buffer('sobel_y', sobel_y)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = F.cross_entropy(logits, targets, weight=self.class_weights)\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        dice_losses = []\n",
    "        num_classes = logits.shape[1]\n",
    "        for cls in range(1, num_classes):\n",
    "            t_cls = (targets == cls).float()\n",
    "            p_cls = probs[:, cls]\n",
    "            inter = (p_cls * t_cls).sum(dim=[1,2])\n",
    "            union = p_cls.sum(dim=[1,2]) + t_cls.sum(dim=[1,2])\n",
    "            dice_score = ((2 * inter + self.smooth) / (union + self.smooth))\n",
    "            dice_losses.append(1 - dice_score)\n",
    "\n",
    "        if dice_losses:\n",
    "            dice_loss = torch.stack(dice_losses, dim=1).mean()\n",
    "        else:\n",
    "            dice_loss = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        # Boundary Loss\n",
    "        pred_mask = torch.argmax(probs, dim=1, keepdim=True).float()\n",
    "        gt_mask = targets.unsqueeze(1).float()\n",
    "\n",
    "        gx_pred = F.conv2d(pred_mask, self.sobel_x, padding=1)\n",
    "        gy_pred = F.conv2d(pred_mask, self.sobel_y, padding=1)\n",
    "        edge_pred = torch.sqrt(gx_pred ** 2 + gy_pred ** 2 + 1e-8)\n",
    "\n",
    "        gx_gt = F.conv2d(gt_mask, self.sobel_x, padding=1)\n",
    "        gy_gt = F.conv2d(gt_mask, self.sobel_y, padding=1)\n",
    "        edge_gt = torch.sqrt(gx_gt ** 2 + gy_gt ** 2 + 1e-8)\n",
    "\n",
    "        edge_mask = (edge_gt > 0.1).float()\n",
    "        if edge_mask.sum() > 0:\n",
    "            boundary_loss = F.l1_loss(edge_pred * edge_mask, edge_gt * edge_mask)\n",
    "        else:\n",
    "            boundary_loss = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        total_loss = (\n",
    "            self.ce_weight * ce_loss +\n",
    "            self.dice_weight * dice_loss +\n",
    "            self.boundary_weight * boundary_loss\n",
    "        )\n",
    "        return total_loss\n",
    "\n",
    "def calculate_improved_weights(data_list, device='cuda'):\n",
    "    \"\"\"클래스 개수 맞춘 개선된 가중치 계산\"\"\"\n",
    "    pixel_counter = Counter()\n",
    "\n",
    "    for rec in data_list:\n",
    "        try:\n",
    "            mask = np.array(Image.open(rec[\"label\"]).convert(\"L\"))\n",
    "            unique, counts = np.unique(mask, return_counts=True)\n",
    "            for cls_id, count in zip(unique, counts):\n",
    "                if 0 <= cls_id <= 6:\n",
    "                    pixel_counter[cls_id] += count\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    fg_pixels = {k: v for k, v in pixel_counter.items() if k > 0}\n",
    "    total_fg = sum(fg_pixels.values())\n",
    "\n",
    "    weights = np.ones(7)\n",
    "    weights[0] = 0.05\n",
    "\n",
    "    for cls_id in range(1, 7):\n",
    "        if cls_id in fg_pixels:\n",
    "            freq = fg_pixels[cls_id] / total_fg\n",
    "            weights[cls_id] = np.sqrt(1.0 / (freq + 1e-6))\n",
    "\n",
    "    weights[1:] = weights[1:] / weights[1:].sum() * 6\n",
    "\n",
    "    print(f\"\\n📊 클래스 가중치:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        class_name = id2label.get(i, f\"class_{i}\")\n",
    "        print(f\"  {class_name}: {w:.3f}\")\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=device)\n",
    "\n",
    "def remove_tiny_noise_with_confidence(pred_mask, single_probs, min_area_ratio=0.003, conf_thresh=0.3, adaptive_thresh=True):\n",
    "    \"\"\"노이즈 제거 함수\"\"\"\n",
    "    H, W = pred_mask.shape\n",
    "    total_pixels = H * W\n",
    "    filtered_mask = np.zeros_like(pred_mask)\n",
    "\n",
    "    for cls_id in np.unique(pred_mask):\n",
    "        if cls_id == 0:\n",
    "            continue\n",
    "\n",
    "        class_mask = (pred_mask == cls_id).astype(np.uint8)\n",
    "        num_labels, labels = cv2.connectedComponents(class_mask)\n",
    "\n",
    "        if adaptive_thresh:\n",
    "            class_confidences = single_probs[cls_id][class_mask == 1]\n",
    "            if len(class_confidences) > 0:\n",
    "                adaptive_conf_thresh = max(conf_thresh, np.percentile(class_confidences, 75))\n",
    "            else:\n",
    "                adaptive_conf_thresh = conf_thresh\n",
    "        else:\n",
    "            adaptive_conf_thresh = conf_thresh\n",
    "\n",
    "        for label_id in range(1, num_labels):\n",
    "            component_mask = (labels == label_id)\n",
    "            area = component_mask.sum()\n",
    "            area_ratio = area / total_pixels\n",
    "\n",
    "            if area_ratio >= min_area_ratio:\n",
    "                filtered_mask[component_mask] = cls_id\n",
    "            else:\n",
    "                comp_confidences = single_probs[cls_id][component_mask]\n",
    "                max_conf = comp_confidences.max() if comp_confidences.size > 0 else 0.0\n",
    "\n",
    "                if max_conf >= adaptive_conf_thresh:\n",
    "                    filtered_mask[component_mask] = cls_id\n",
    "\n",
    "    return filtered_mask\n",
    "\n",
    "def refine_mask_morphology(mask, kernel_size=5):\n",
    "    \"\"\"형태학적 연산\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    opened = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    return closed\n",
    "\n",
    "def gentle_predict(batch, model, input_size=512, num_classes=10, confidence_threshold=None, use_multiscale=False, use_tta=False):\n",
    "    \"\"\"예측 함수\"\"\"\n",
    "    imgs = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if use_tta:\n",
    "            tta_preds = []\n",
    "            \n",
    "            # 원본\n",
    "            outputs = model(pixel_values=imgs)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            tta_preds.append(F.softmax(logits, dim=1))\n",
    "\n",
    "            # 좌우 반전\n",
    "            imgs_h_flipped = torch.flip(imgs, dims=[3])\n",
    "            outputs = model(pixel_values=imgs_h_flipped)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            logits_h_flipped_back = torch.flip(logits, dims=[3])\n",
    "            tta_preds.append(F.softmax(logits_h_flipped_back, dim=1))\n",
    "\n",
    "            probs = torch.stack(tta_preds).mean(dim=0)\n",
    "        else:\n",
    "            outputs = model(pixel_values=imgs)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        filtered_pred_list = []\n",
    "        for i in range(probs.shape[0]):\n",
    "            single_probs = probs[i].cpu().numpy()\n",
    "            pred_mask = np.argmax(single_probs, axis=0)\n",
    "\n",
    "            filtered1 = remove_tiny_noise_with_confidence(\n",
    "                pred_mask, single_probs, min_area_ratio=0.003, conf_thresh=0.3, adaptive_thresh=True\n",
    "            )\n",
    "            filtered2 = refine_mask_morphology(filtered1, kernel_size=5)\n",
    "            \n",
    "            filtered_pred_list.append(torch.tensor(filtered2, device=device))\n",
    "\n",
    "        pred = torch.stack(filtered_pred_list)\n",
    "\n",
    "    return probs, pred\n",
    "\n",
    "def improved_training(model, train_loader, val_loader, processor, class_weights_tensor,\n",
    "                     max_epochs=400, patience=40, device='cuda',\n",
    "                     use_enhanced_loss=False, use_advanced_scheduler=False):\n",
    "    \"\"\"학습 함수\"\"\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    model = model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4, eps=1e-8)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=12,\n",
    "                                  threshold=0.005, min_lr=1e-6, verbose=True)\n",
    "\n",
    "    criterion = CombinedBoundaryLoss(\n",
    "        class_weights=class_weights_tensor,\n",
    "        dice_weight=0.5,\n",
    "        ce_weight=0.3,\n",
    "        boundary_weight=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'dice_scores': [], 'iou_scores': [], 'learning_rates': []}\n",
    "    best_dice = 0.0\n",
    "    early_stop_counter = 0\n",
    "    best_model_path = os.path.join(base_dir, \"results\", \"best_model\")\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            masks = batch[\"labels\"].to(device)\n",
    "            masks = torch.clamp(masks, 0, 9)\n",
    "            masks = F.interpolate(\n",
    "                masks.unsqueeze(1).float(),\n",
    "                size=(512, 512),\n",
    "                mode='nearest'\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(pixel_values=imgs)\n",
    "                logits = outputs.logits\n",
    "                logits = F.interpolate(logits, size=(512, 512), mode='bilinear')\n",
    "                loss = criterion(logits, masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Validation\n",
    "        val_dice, val_iou = evaluate_model_fairly(model, val_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                imgs = batch[\"pixel_values\"].to(device)\n",
    "                masks = batch[\"labels\"].to(device)\n",
    "                masks = torch.clamp(masks, 0, 9)\n",
    "                masks = F.interpolate(\n",
    "                    masks.unsqueeze(1).float(),\n",
    "                    size=(512, 512),\n",
    "                    mode='nearest'\n",
    "                ).squeeze(1).long()\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(pixel_values=imgs)\n",
    "                    logits = outputs.logits\n",
    "                    logits = F.interpolate(logits, size=(512, 512), mode='bilinear')\n",
    "                    loss = criterion(logits, masks)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        avg_val_loss = np.mean(val_losses) if val_losses else float('inf')\n",
    "\n",
    "        scheduler.step(val_dice)\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['dice_scores'].append(val_dice)\n",
    "        history['iou_scores'].append(val_iou)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{max_epochs}  ▶  Train Loss: {avg_train_loss:.4f}  |  Val Loss: {avg_val_loss:.4f}  |  Dice: {val_dice:.4f}  |  IoU: {val_iou:.4f}  |  LR: {current_lr:.2e}\")\n",
    "\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            try:\n",
    "                os.makedirs(best_model_path, exist_ok=True)\n",
    "                model.eval()\n",
    "                model.save_pretrained(best_model_path, safe_serialization=False)\n",
    "                processor.save_pretrained(best_model_path)\n",
    "                print(f\"✅ New Best! Dice {val_dice:.4f} 저장 완료\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 모델 저장 실패: {e}\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"\\n🛑 Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    return history, best_model_path\n",
    "\n",
    "def evaluate_model_fairly(model, val_loader, use_strict=False):\n",
    "    \"\"\"모델 평가\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            _, preds = gentle_predict(batch, model, 512, 10)\n",
    "\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "            targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=(512, 512),\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    if all_preds and all_targets:\n",
    "        pred_flat = np.concatenate([p.flatten() for p in all_preds])\n",
    "        target_flat = np.concatenate([t.flatten() for t in all_targets])\n",
    "        dice, iou, _ = calculate_advanced_metrics(pred_flat, target_flat, 10)\n",
    "        return dice, iou\n",
    "\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def calculate_advanced_metrics(pred, target, num_classes):\n",
    "    \"\"\"메트릭 계산\"\"\"\n",
    "    pred = np.array(pred).flatten()\n",
    "    target = np.array(target).flatten()\n",
    "\n",
    "    valid_mask = target != 0\n",
    "    pred_valid = pred[valid_mask]\n",
    "    target_valid = target[valid_mask]\n",
    "\n",
    "    if len(target_valid) == 0:\n",
    "        return 0.0, 0.0, np.zeros(num_classes)\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    precision_scores = np.zeros(num_classes)\n",
    "\n",
    "    for cls in range(1, num_classes):\n",
    "        pred_cls = (pred_valid == cls)\n",
    "        target_cls = (target_valid == cls)\n",
    "\n",
    "        if target_cls.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        intersection = (pred_cls & target_cls).sum()\n",
    "        union = (pred_cls | target_cls).sum()\n",
    "\n",
    "        if union > 0:\n",
    "            iou = intersection / union\n",
    "            dice = (2 * intersection) / (pred_cls.sum() + target_cls.sum())\n",
    "            iou_scores.append(iou)\n",
    "            dice_scores.append(dice)\n",
    "\n",
    "        if pred_cls.sum() > 0:\n",
    "            precision_scores[cls] = intersection / pred_cls.sum()\n",
    "\n",
    "    return (np.mean(dice_scores) if dice_scores else 0.0,\n",
    "            np.mean(iou_scores) if iou_scores else 0.0,\n",
    "            precision_scores)\n",
    "\n",
    "# ===============================================================================\n",
    "# 🎨 STEP 3: 시각화 함수들\n",
    "# ===============================================================================\n",
    "\n",
    "def mask_to_color_rgb(mask):\n",
    "    \"\"\"마스크를 RGB 컬러 이미지로 변환\"\"\"\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                color_mask[class_mask] = color\n",
    "    \n",
    "    return color_mask\n",
    "\n",
    "def add_readable_center_labels(image, mask, class_names, label_scale=0.6):\n",
    "    \"\"\"각 세그먼트의 중심에 읽기 쉬운 라벨 추가\"\"\"\n",
    "    labeled_image = image.copy()\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        class_mask = (mask == class_id)\n",
    "        if class_mask.any():\n",
    "            coords = np.where(class_mask)\n",
    "            center_y = int(np.mean(coords[0]))\n",
    "            center_x = int(np.mean(coords[1]))\n",
    "            \n",
    "            label_text = class_names[class_id]\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = label_scale\n",
    "            thickness = 2\n",
    "            \n",
    "            (text_w, text_h), baseline = cv2.getTextSize(label_text, font, font_scale, thickness)\n",
    "            \n",
    "            box_x1 = max(0, center_x - text_w // 2 - 5)\n",
    "            box_y1 = max(0, center_y - text_h // 2 - 5)\n",
    "            box_x2 = min(image.shape[1], center_x + text_w // 2 + 5)\n",
    "            box_y2 = min(image.shape[0], center_y + text_h // 2 + 5)\n",
    "            \n",
    "            cv2.rectangle(labeled_image, (box_x1, box_y1), (box_x2, box_y2), (0, 0, 0), -1)\n",
    "            \n",
    "            text_x = center_x - text_w // 2\n",
    "            text_y = center_y + text_h // 2\n",
    "            cv2.putText(labeled_image, label_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)\n",
    "    \n",
    "    return labeled_image\n",
    "\n",
    "def visualize_with_transparent_background(image, mask, alpha=0.7):\n",
    "    \"\"\"배경은 투명하게, 객체들만 색칠해서 오버레이\"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                color_overlay = np.full_like(image[class_mask], color)\n",
    "                result[class_mask] = cv2.addWeighted(\n",
    "                    image[class_mask], 1-alpha,\n",
    "                    color_overlay, alpha,\n",
    "                    0\n",
    "                )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_pure_mask_visualization(mask):\n",
    "    \"\"\"순수 마스크 시각화 (배경 완전 투명)\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgba_image = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                rgba_image[class_mask] = [color[0], color[1], color[2], 255]\n",
    "    \n",
    "    return rgba_image\n",
    "\n",
    "def save_prediction_comparison_readable(image_tensor, true_mask, pred_mask, save_path, original_image_path):\n",
    "    \"\"\"완벽한 예측 비교 저장\"\"\"\n",
    "    if original_image_path and os.path.exists(original_image_path):\n",
    "        orig_img = PILImage.open(original_image_path).convert('RGB')\n",
    "        image_np = np.array(orig_img)\n",
    "\n",
    "        if image_np.shape[:2] != (512, 512):\n",
    "            image_np = cv2.resize(image_np, (512, 512))\n",
    "\n",
    "    else:\n",
    "        if torch.is_tensor(image_tensor):\n",
    "            image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "            if image_np.min() >= -3 and image_np.max() <= 3:\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image_np = image_np * std + mean\n",
    "                image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "            if image_np.max() <= 1:\n",
    "                image_np = (image_np * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image_np = image_np.astype(np.uint8)\n",
    "        else:\n",
    "            image_np = image_tensor\n",
    "\n",
    "        if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "            image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "            image_np = np.ascontiguousarray(image_np, dtype=np.uint8)\n",
    "\n",
    "    target_h, target_w = image_np.shape[:2]\n",
    "    if true_mask.shape != (target_h, target_w):\n",
    "        true_mask = cv2.resize(true_mask.astype(np.uint8), (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "    if pred_mask.shape != (target_h, target_w):\n",
    "        pred_mask = cv2.resize(pred_mask.astype(np.uint8), (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    true_color_rgb = mask_to_color_rgb(true_mask)\n",
    "    pred_color_rgb = mask_to_color_rgb(pred_mask)\n",
    "    \n",
    "    true_with_labels = add_readable_center_labels(true_color_rgb.copy(), true_mask, class_names, label_scale=0.7)\n",
    "    pred_with_labels = add_readable_center_labels(pred_color_rgb.copy(), pred_mask, class_names, label_scale=0.7)\n",
    "\n",
    "    transparent_overlay = visualize_with_transparent_background(image_np, pred_mask, alpha=0.6)\n",
    "    overlay_with_labels = add_readable_center_labels(transparent_overlay.copy(), pred_mask, class_names, label_scale=0.6)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    axes[0].imshow(image_np)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(true_with_labels)\n",
    "    axes[1].set_title(\"Ground Truth\", fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(pred_with_labels)\n",
    "    axes[2].set_title(\"Prediction\", fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    axes[3].imshow(overlay_with_labels)\n",
    "    axes[3].set_title(\"Transparent Overlay\", fontsize=12, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ===============================================================================\n",
    "# 🗂️ STEP 4: 결과 저장 시스템\n",
    "# ===============================================================================\n",
    "\n",
    "def clean_save_all_results(model, val_loader, processor, history, final_dice, final_iou, \n",
    "                          best_model_path, save_base_dir=None):\n",
    "    \"\"\"깔끔한 결과 저장\"\"\"\n",
    "    if save_base_dir is None:\n",
    "        save_base_dir = os.path.join(base_dir, \"results\")\n",
    "    \n",
    "    print(\"🗂️ 깔끔한 결과 저장 시작...\")\n",
    "    \n",
    "    viz_dir = os.path.join(save_base_dir, \"visualizations\")\n",
    "    perf_dir = os.path.join(save_base_dir, \"performance\")\n",
    "    \n",
    "    if os.path.exists(viz_dir):\n",
    "        shutil.rmtree(viz_dir)\n",
    "    if os.path.exists(perf_dir):\n",
    "        shutil.rmtree(perf_dir)\n",
    "    \n",
    "    os.makedirs(save_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Best Model 확인\n",
    "    model_save_dir = os.path.join(save_base_dir, \"best_model\")\n",
    "    if os.path.exists(model_save_dir):\n",
    "        files = os.listdir(model_save_dir)\n",
    "        if files:\n",
    "            print(f\"✅ 1. Best Model 확인됨: {model_save_dir}\")\n",
    "        else:\n",
    "            print(f\"⚠️ 1. Best Model 폴더는 있지만 비어있음\")\n",
    "    else:\n",
    "        print(f\"❌ 1. Best Model 폴더 없음: {model_save_dir}\")\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        model.save_pretrained(model_save_dir, safe_serialization=False)\n",
    "        processor.save_pretrained(model_save_dir)\n",
    "        print(f\"✅ 1. Current Model 저장: {model_save_dir}\")\n",
    "    \n",
    "    # 모든 예측 결과 시각화 저장\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    print(\"🎨 2. 모든 예측 결과 시각화 저장 중...\")\n",
    "    total_saved = save_all_prediction_visualizations(model, val_loader, viz_dir)\n",
    "    print(f\"✅ 2. 시각화 완료: {total_saved}개 이미지 → {viz_dir}\")\n",
    "    \n",
    "    # 성능 결과 저장\n",
    "    os.makedirs(perf_dir, exist_ok=True)\n",
    "    \n",
    "    save_training_graphs(history, os.path.join(perf_dir, \"training_history.png\"))\n",
    "    save_performance_report(history, final_dice, final_iou, os.path.join(perf_dir, \"performance_report.txt\"))\n",
    "    \n",
    "    print(f\"✅ 3. 성능 결과 저장: {perf_dir}\")\n",
    "    \n",
    "    print(f\"\\n🎉 깔끔한 저장 완료!\")\n",
    "    print(f\"📁 저장 위치: {save_base_dir}\")\n",
    "    print(f\"📊 구조:\")\n",
    "    print(f\"  ├── best_model/        (학습된 모델)\")\n",
    "    print(f\"  ├── visualizations/    ({total_saved}개 예측 시각화)\")\n",
    "    print(f\"  └── performance/       (성능 그래프 + 리포트)\")\n",
    "    \n",
    "    return save_base_dir\n",
    "\n",
    "def save_all_prediction_visualizations(model, val_loader, save_dir):\n",
    "    \"\"\"모든 validation 데이터의 예측 결과를 4패널로 시각화하여 저장\"\"\"\n",
    "    model.eval()\n",
    "    total_saved = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"시각화 저장\")):\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            filenames = batch[\"filename\"]\n",
    "            \n",
    "            _, preds = gentle_predict(batch, model, 512, len(class_names))\n",
    "            \n",
    "            batch_size = imgs.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                img_path = batch[\"original_image_path\"][i]\n",
    "                img_np = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "                \n",
    "                gt_mask = labels[i].cpu().numpy().astype(np.uint8)\n",
    "                pred_mask = preds[i].cpu().numpy().astype(np.uint8)\n",
    "                \n",
    "                filename = f\"prediction_{batch_idx:03d}_{i:02d}_{os.path.splitext(filenames[i])[0]}.png\"\n",
    "                save_path = os.path.join(save_dir, filename)\n",
    "                \n",
    "                create_4panel_visualization(img_np, gt_mask, pred_mask, save_path)\n",
    "                total_saved += 1\n",
    "    \n",
    "    return total_saved\n",
    "\n",
    "def create_4panel_visualization(img_np, gt_mask, pred_mask, save_path):\n",
    "    \"\"\"4패널 시각화: 원본 + GT + 예측 + 오버레이\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axes[0].imshow(img_np)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    gt_color = mask_to_color_rgb(gt_mask)\n",
    "    gt_with_labels = add_readable_center_labels(gt_color.copy(), gt_mask, class_names, label_scale=0.7)\n",
    "    axes[1].imshow(gt_with_labels)\n",
    "    axes[1].set_title(\"Ground Truth\", fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    pred_color = mask_to_color_rgb(pred_mask)\n",
    "    pred_with_labels = add_readable_center_labels(pred_color.copy(), pred_mask, class_names, label_scale=0.7)\n",
    "    axes[2].imshow(pred_with_labels)\n",
    "    axes[2].set_title(\"Prediction\", fontsize=14, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    overlay = create_overlay(img_np, pred_mask, alpha=0.4)\n",
    "    overlay_with_labels = add_readable_center_labels(overlay, pred_mask, class_names, label_scale=0.6)\n",
    "    axes[3].imshow(overlay_with_labels)\n",
    "    axes[3].set_title(\"Overlay\", fontsize=14, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "def create_overlay(img_np, pred_mask, alpha=0.4):\n",
    "    \"\"\"원본 이미지 + 예측 마스크 오버레이\"\"\"\n",
    "    overlay = img_np.copy().astype(np.float32)\n",
    "    color_mask = mask_to_color_rgb(pred_mask).astype(np.float32)\n",
    "    \n",
    "    mask_area = (pred_mask > 0)\n",
    "    overlay[mask_area] = (\n",
    "        overlay[mask_area] * (1 - alpha) + \n",
    "        color_mask[mask_area] * alpha\n",
    "    )\n",
    "    \n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "def save_training_graphs(history, save_path):\n",
    "    \"\"\"학습 히스토리 그래프 저장\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', color='red', linewidth=2)\n",
    "    axes[0, 0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(history['dice_scores'], label='Dice Score', color='green', linewidth=2)\n",
    "    axes[0, 1].set_title('Dice Score', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].plot(history['iou_scores'], label='IoU Score', color='orange', linewidth=2)\n",
    "    axes[1, 0].set_title('IoU Score', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('IoU Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if 'learning_rates' in history:\n",
    "        axes[1, 1].plot(history['learning_rates'], label='Learning Rate', color='purple', linewidth=2)\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].set_yscale('log')\n",
    "    else:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "def save_performance_report(history, final_dice, final_iou, save_path):\n",
    "    \"\"\"성능 리포트 텍스트 파일 저장\"\"\"\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"🎯 Recycle Segmentation 성능 리포트\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"📊 학습 결과:\\n\")\n",
    "        f.write(f\"  • 총 에포크: {len(history['train_loss'])}\\n\")\n",
    "        f.write(f\"  • 최종 Train Loss: {history['train_loss'][-1]:.4f}\\n\")\n",
    "        f.write(f\"  • 최종 Val Loss: {history['val_loss'][-1]:.4f}\\n\")\n",
    "        f.write(f\"  • 최고 Dice Score: {max(history['dice_scores']):.4f}\\n\")\n",
    "        f.write(f\"  • 최고 IoU Score: {max(history['iou_scores']):.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"🎯 최종 성능:\\n\")\n",
    "        f.write(f\"  • Dice Score: {final_dice:.4f}\\n\")\n",
    "        f.write(f\"  • IoU Score: {final_iou:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"📈 성능 평가:\\n\")\n",
    "        if final_dice > 0.85:\n",
    "            f.write(\"  ✅ 우수한 성능! 실제 배포 가능한 수준\\n\")\n",
    "        elif final_dice > 0.7:\n",
    "            f.write(\"  🟢 좋은 성능! 실용적으로 사용 가능\\n\")\n",
    "        elif final_dice > 0.5:\n",
    "            f.write(\"  🟡 보통 성능. 추가 개선으로 향상 가능\\n\")\n",
    "        else:\n",
    "            f.write(\"  🔴 성능 부족. 추가 튜닝 필요\\n\")\n",
    "\n",
    "# ===============================================================================\n",
    "# 🚀 STEP 5: 메인 파이프라인 실행\n",
    "# ===============================================================================\n",
    "\n",
    "def calculate_class_weights_from_pixel_counter(pixel_counter):\n",
    "    \"\"\"픽셀 카운터로부터 클래스 가중치 계산\"\"\"\n",
    "    print(\"\\n📊 클래스 가중치 계산 중...\")\n",
    "    \n",
    "    total_pixels = sum(pixel_counter.values())\n",
    "    \n",
    "    class_weights = []\n",
    "    for class_id in range(len(class_names)):\n",
    "        if class_id in pixel_counter and pixel_counter[class_id] > 0:\n",
    "            weight = total_pixels / (len(class_names) * pixel_counter[class_id])\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        class_weights.append(weight)\n",
    "    \n",
    "    max_weight = max(class_weights)\n",
    "    if max_weight > 10:\n",
    "        class_weights = [w / max_weight * 10 for w in class_weights]\n",
    "    \n",
    "    class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "    \n",
    "    print(\"🎯 클래스별 가중치:\")\n",
    "    for i, (class_name, weight) in enumerate(zip(class_names, class_weights)):\n",
    "        pixel_count = pixel_counter.get(i, 0)\n",
    "        print(f\"   {class_name}: {weight:.3f} (픽셀 수: {pixel_count:,})\")\n",
    "    \n",
    "    return class_weights_tensor\n",
    "\n",
    "def run_clean_pipeline():\n",
    "    \"\"\"완전한 파이프라인 실행\"\"\"\n",
    "    print(\"🚀 깔끔한 Recycle Segmentation 파이프라인 시작!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # STEP 1: 데이터 전처리\n",
    "        print(\"\\n📊 STEP 1: 데이터 전처리 시작\")\n",
    "        final_data_list, pixel_counter = preprocess_datasets()\n",
    "\n",
    "        if len(final_data_list) == 0:\n",
    "            print(\"❌ 처리할 데이터가 없습니다!\")\n",
    "            return\n",
    "\n",
    "        print(f\"✅ 전처리 완료: {len(final_data_list)}개 데이터\")\n",
    "\n",
    "        # STEP 2: 클래스 가중치 계산\n",
    "        print(\"\\n🔧 STEP 2: 클래스 가중치 계산\")\n",
    "        \n",
    "        class_weights_tensor = calculate_class_weights_from_pixel_counter(pixel_counter).to(device)\n",
    "        print(f\"✅ 클래스 가중치 계산 완료\")\n",
    "\n",
    "        # 모델 로딩\n",
    "        print(\"\\n🤖 모델 및 프로세서 로딩 중...\")\n",
    "        processor = AutoImageProcessor.from_pretrained(\"apple/deeplabv3-mobilevit-small\", use_fast=True)\n",
    "        model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "            \"apple/deeplabv3-mobilevit-small\",\n",
    "            num_labels=len(class_names),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        print(\"✅ 모델 로딩 완료\")\n",
    "\n",
    "        # Train/Val 분할\n",
    "        print(\"\\n📊 Train/Val 데이터 분할 중...\")\n",
    "        random.seed(42)\n",
    "        random.shuffle(final_data_list)\n",
    "        \n",
    "        split_idx = int(len(final_data_list) * 0.8)\n",
    "        train_list = final_data_list[:split_idx]\n",
    "        val_list = final_data_list[split_idx:]\n",
    "\n",
    "        print(f\"📊 데이터 분할 완료: Train {len(train_list)}개, Val {len(val_list)}개\")\n",
    "\n",
    "        # 데이터셋 생성\n",
    "        train_ds = create_clean_dataset(train_list, processor, input_size=512)\n",
    "        val_ds = create_clean_dataset(val_list, processor, input_size=512)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        print(f\"✅ DataLoader 생성 완료: Train batches {len(train_loader)}, Val batches {len(val_loader)}\")\n",
    "\n",
    "        # STEP 3: 모델 학습\n",
    "        print(\"\\n🚀 STEP 3: 모델 학습 시작\")\n",
    "        history, best_model_path = improved_training(\n",
    "            model, train_loader, val_loader, processor, class_weights_tensor,\n",
    "            max_epochs=200, patience=30, device=device\n",
    "        )\n",
    "\n",
    "        # Best 모델 로딩\n",
    "        if best_model_path and os.path.exists(best_model_path):\n",
    "            print(f\"\\n📥 Best 모델 로딩 중: {best_model_path}\")\n",
    "            try:\n",
    "                model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "                    best_model_path, local_files_only=True\n",
    "                ).to(device)\n",
    "                processor = AutoImageProcessor.from_pretrained(best_model_path)\n",
    "                print(\"✅ Best 모델 로딩 완료!\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Best 모델 로딩 실패: {e}\")\n",
    "\n",
    "        # 최종 성능 평가\n",
    "        print(\"\\n📊 최종 성능 평가 중...\")\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                _, pred = gentle_predict(batch, model, 512, len(class_names))\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_targets.append(batch[\"labels\"].cpu().numpy())\n",
    "        \n",
    "        pred_flat = np.concatenate([p.flatten() for p in all_preds])\n",
    "        target_flat = np.concatenate([t.flatten() for t in all_targets])\n",
    "        final_dice, final_iou, _ = calculate_advanced_metrics(pred_flat, target_flat, len(class_names))\n",
    "\n",
    "        # STEP 4: 결과 저장\n",
    "        print(\"\\n🗂️ STEP 4: 깔끔한 결과 저장\")\n",
    "        save_dir = clean_save_all_results(\n",
    "            model, val_loader, processor, history, \n",
    "            final_dice, final_iou, best_model_path\n",
    "        )\n",
    "\n",
    "        print(f\"\\n🎉 완료! 모든 결과가 저장되었습니다:\")\n",
    "        print(f\"📁 {save_dir}\")\n",
    "        print(f\"📊 최종 성능: Dice {final_dice:.4f}, IoU {final_iou:.4f}\")\n",
    "\n",
    "        return save_dir\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ 파이프라인 실행 중 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    run_clean_pipeline()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
