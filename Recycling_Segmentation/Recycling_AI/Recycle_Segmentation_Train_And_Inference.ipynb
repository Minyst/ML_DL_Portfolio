{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—‚ï¸ ë°ì´í„° ì •ë¦¬ ì‹œì‘...\n",
      "ğŸ“ train í´ë”ì—ì„œ ì°¾ì€ ì´ë¯¸ì§€: 930ê°œ\n",
      "ğŸ“ train í´ë”ì—ì„œ ì°¾ì€ ë§ˆìŠ¤í¬: 930ê°œ\n",
      "âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ!\n",
      "   ğŸ“ ì´ë¯¸ì§€: 930ê°œ â†’ datasets/images/\n",
      "   ğŸ“ ë§ˆìŠ¤í¬: 930ê°œ â†’ datasets/masks/\n",
      "ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n",
      "ğŸš€ ê¹”ë”í•œ Recycle Segmentation íŒŒì´í”„ë¼ì¸ ì‹œì‘!\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š STEP 1: ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š STEP 1: datasets í´ë” ë°ì´í„° ë§¤ì¹­ ì‹œì‘\n",
      "ğŸ“ JPG ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: 930ê°œ\n",
      "ğŸ“ PNG ë§ˆìŠ¤í¬ íŒŒì¼ ê°œìˆ˜: 930ê°œ\n",
      "âœ… ìˆ«ì ê¸°ë°˜ ë§¤ì¹­ ì„±ê³µ: 930ê°œ\n",
      "ğŸ” ë§¤ì¹­ëœ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ: 930ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ë§¤ì¹­: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 930/930 [00:02<00:00, 423.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ë°ì´í„° ê°œìˆ˜: 930ê°œ\n",
      "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: 930ê°œ ë°ì´í„°\n",
      "\n",
      "ğŸ”§ STEP 2: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
      "\n",
      "ğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...\n",
      "ğŸ¯ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜:\n",
      "   background: 0.195 (í”½ì…€ ìˆ˜: 178,471,959)\n",
      "   can: 5.586 (í”½ì…€ ìˆ˜: 6,234,788)\n",
      "   glass: 5.579 (í”½ì…€ ìˆ˜: 6,242,213)\n",
      "   paper: 4.862 (í”½ì…€ ìˆ˜: 7,163,569)\n",
      "   plastic: 2.850 (í”½ì…€ ìˆ˜: 12,220,847)\n",
      "   styrofoam: 3.296 (í”½ì…€ ìˆ˜: 10,565,234)\n",
      "   vinyl: 1.521 (í”½ì…€ ìˆ˜: 22,895,310)\n",
      "âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë”© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\transformers\\utils\\generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\transformers\\modeling_utils.py:484: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "Some weights of MobileViTForSemanticSegmentation were not initialized from the model checkpoint at apple/deeplabv3-mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- segmentation_head.classifier.convolution.weight: found shape torch.Size([21, 256, 1, 1]) in the checkpoint and torch.Size([7, 256, 1, 1]) in the model instantiated\n",
      "- segmentation_head.classifier.convolution.bias: found shape torch.Size([21]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\n",
      "\n",
      "ğŸ“Š Train/Val ë°ì´í„° ë¶„í•  ì¤‘...\n",
      "ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train 744ê°œ, Val 186ê°œ\n",
      "ğŸ” í•„í„°ë§ ì—†ëŠ” ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\n",
      "ğŸ“Š ì…ë ¥ ë°ì´í„° ê°œìˆ˜: 744ê°œ\n",
      "ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸°: 744ê°œ\n",
      "âœ… ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸°: 744ê°œ\n",
      "ğŸ” í•„í„°ë§ ì—†ëŠ” ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\n",
      "ğŸ“Š ì…ë ¥ ë°ì´í„° ê°œìˆ˜: 186ê°œ\n",
      "ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸°: 186ê°œ\n",
      "âœ… ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸°: 186ê°œ\n",
      "âœ… DataLoader ìƒì„± ì™„ë£Œ: Train batches 46, Val batches 12\n",
      "\n",
      "ğŸš€ STEP 3: ëª¨ë¸ í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:483: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "c:\\Users\\USER\\anaconda3\\envs\\cvl\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:517: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_3820\\2917448145.py:550: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200  â–¶  Train Loss: 1.0833  |  Val Loss: 1.0572  |  Dice: 0.4425  |  IoU: 0.2943  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.4425 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 2/200  â–¶  Train Loss: 1.0428  |  Val Loss: 1.0124  |  Dice: 0.6619  |  IoU: 0.5223  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.6619 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 3/200  â–¶  Train Loss: 0.9948  |  Val Loss: 0.9483  |  Dice: 0.8392  |  IoU: 0.7391  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.8392 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 4/200  â–¶  Train Loss: 0.9270  |  Val Loss: 0.8712  |  Dice: 0.8935  |  IoU: 0.8166  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.8935 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 5/200  â–¶  Train Loss: 0.8556  |  Val Loss: 0.8046  |  Dice: 0.9091  |  IoU: 0.8395  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9091 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 6/200  â–¶  Train Loss: 0.7926  |  Val Loss: 0.7363  |  Dice: 0.9326  |  IoU: 0.8772  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9326 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 7/200  â–¶  Train Loss: 0.7384  |  Val Loss: 0.6944  |  Dice: 0.9397  |  IoU: 0.8893  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9397 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 8/200  â–¶  Train Loss: 0.6970  |  Val Loss: 0.6613  |  Dice: 0.9549  |  IoU: 0.9154  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9549 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 9/200  â–¶  Train Loss: 0.6692  |  Val Loss: 0.6260  |  Dice: 0.9642  |  IoU: 0.9321  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9642 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 10/200  â–¶  Train Loss: 0.6390  |  Val Loss: 0.6049  |  Dice: 0.9681  |  IoU: 0.9393  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9681 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 11/200  â–¶  Train Loss: 0.6171  |  Val Loss: 0.5823  |  Dice: 0.9727  |  IoU: 0.9478  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9727 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 12/200  â–¶  Train Loss: 0.6005  |  Val Loss: 0.5703  |  Dice: 0.9814  |  IoU: 0.9638  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9814 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 13/200  â–¶  Train Loss: 0.5844  |  Val Loss: 0.5570  |  Dice: 0.9819  |  IoU: 0.9647  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9819 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 14/200  â–¶  Train Loss: 0.5674  |  Val Loss: 0.5458  |  Dice: 0.9824  |  IoU: 0.9659  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9824 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 15/200  â–¶  Train Loss: 0.5531  |  Val Loss: 0.5327  |  Dice: 0.9839  |  IoU: 0.9687  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9839 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 16/200  â–¶  Train Loss: 0.5407  |  Val Loss: 0.5215  |  Dice: 0.9848  |  IoU: 0.9704  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9848 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 17/200  â–¶  Train Loss: 0.5252  |  Val Loss: 0.5124  |  Dice: 0.9855  |  IoU: 0.9717  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9855 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 18/200  â–¶  Train Loss: 0.5175  |  Val Loss: 0.5030  |  Dice: 0.9862  |  IoU: 0.9730  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9862 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 19/200  â–¶  Train Loss: 0.5071  |  Val Loss: 0.4991  |  Dice: 0.9808  |  IoU: 0.9629  |  LR: 1.00e-04\n",
      "Epoch 20/200  â–¶  Train Loss: 0.5000  |  Val Loss: 0.4898  |  Dice: 0.9859  |  IoU: 0.9725  |  LR: 1.00e-04\n",
      "Epoch 21/200  â–¶  Train Loss: 0.4922  |  Val Loss: 0.4860  |  Dice: 0.9856  |  IoU: 0.9719  |  LR: 1.00e-04\n",
      "Epoch 22/200  â–¶  Train Loss: 0.4833  |  Val Loss: 0.4768  |  Dice: 0.9866  |  IoU: 0.9737  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9866 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 23/200  â–¶  Train Loss: 0.4763  |  Val Loss: 0.4719  |  Dice: 0.9872  |  IoU: 0.9750  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9872 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 24/200  â–¶  Train Loss: 0.4726  |  Val Loss: 0.4677  |  Dice: 0.9877  |  IoU: 0.9758  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9877 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 25/200  â–¶  Train Loss: 0.4646  |  Val Loss: 0.4646  |  Dice: 0.9860  |  IoU: 0.9727  |  LR: 1.00e-04\n",
      "Epoch 26/200  â–¶  Train Loss: 0.4623  |  Val Loss: 0.4613  |  Dice: 0.9865  |  IoU: 0.9737  |  LR: 1.00e-04\n",
      "Epoch 27/200  â–¶  Train Loss: 0.4569  |  Val Loss: 0.4575  |  Dice: 0.9869  |  IoU: 0.9744  |  LR: 1.00e-04\n",
      "Epoch 28/200  â–¶  Train Loss: 0.4536  |  Val Loss: 0.4552  |  Dice: 0.9873  |  IoU: 0.9751  |  LR: 1.00e-04\n",
      "Epoch 29/200  â–¶  Train Loss: 0.4515  |  Val Loss: 0.4520  |  Dice: 0.9882  |  IoU: 0.9768  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9882 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 30/200  â–¶  Train Loss: 0.4501  |  Val Loss: 0.4499  |  Dice: 0.9877  |  IoU: 0.9759  |  LR: 1.00e-04\n",
      "Epoch 31/200  â–¶  Train Loss: 0.4484  |  Val Loss: 0.4484  |  Dice: 0.9875  |  IoU: 0.9755  |  LR: 1.00e-04\n",
      "Epoch 32/200  â–¶  Train Loss: 0.4494  |  Val Loss: 0.4473  |  Dice: 0.9880  |  IoU: 0.9764  |  LR: 1.00e-04\n",
      "Epoch 33/200  â–¶  Train Loss: 0.4449  |  Val Loss: 0.4457  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9886 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 34/200  â–¶  Train Loss: 0.4408  |  Val Loss: 0.4450  |  Dice: 0.9887  |  IoU: 0.9777  |  LR: 1.00e-04\n",
      "âœ… New Best! Dice 0.9887 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 35/200  â–¶  Train Loss: 0.4387  |  Val Loss: 0.4461  |  Dice: 0.9864  |  IoU: 0.9734  |  LR: 1.00e-04\n",
      "Epoch 36/200  â–¶  Train Loss: 0.4369  |  Val Loss: 0.4428  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 37/200  â–¶  Train Loss: 0.4362  |  Val Loss: 0.4413  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 7.00e-05\n",
      "âœ… New Best! Dice 0.9890 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 38/200  â–¶  Train Loss: 0.4348  |  Val Loss: 0.4411  |  Dice: 0.9888  |  IoU: 0.9780  |  LR: 7.00e-05\n",
      "Epoch 39/200  â–¶  Train Loss: 0.4345  |  Val Loss: 0.4400  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 40/200  â–¶  Train Loss: 0.4339  |  Val Loss: 0.4398  |  Dice: 0.9885  |  IoU: 0.9774  |  LR: 7.00e-05\n",
      "Epoch 41/200  â–¶  Train Loss: 0.4327  |  Val Loss: 0.4396  |  Dice: 0.9884  |  IoU: 0.9772  |  LR: 7.00e-05\n",
      "Epoch 42/200  â–¶  Train Loss: 0.4320  |  Val Loss: 0.4393  |  Dice: 0.9889  |  IoU: 0.9782  |  LR: 7.00e-05\n",
      "Epoch 43/200  â–¶  Train Loss: 0.4324  |  Val Loss: 0.4385  |  Dice: 0.9885  |  IoU: 0.9773  |  LR: 7.00e-05\n",
      "Epoch 44/200  â–¶  Train Loss: 0.4313  |  Val Loss: 0.4380  |  Dice: 0.9886  |  IoU: 0.9776  |  LR: 7.00e-05\n",
      "Epoch 45/200  â–¶  Train Loss: 0.4308  |  Val Loss: 0.4376  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 7.00e-05\n",
      "âœ… New Best! Dice 0.9891 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 46/200  â–¶  Train Loss: 0.4294  |  Val Loss: 0.4378  |  Dice: 0.9885  |  IoU: 0.9774  |  LR: 7.00e-05\n",
      "Epoch 47/200  â–¶  Train Loss: 0.4298  |  Val Loss: 0.4364  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 7.00e-05\n",
      "Epoch 48/200  â–¶  Train Loss: 0.4283  |  Val Loss: 0.4360  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 7.00e-05\n",
      "âœ… New Best! Dice 0.9894 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 49/200  â–¶  Train Loss: 0.4272  |  Val Loss: 0.4356  |  Dice: 0.9892  |  IoU: 0.9787  |  LR: 4.90e-05\n",
      "Epoch 50/200  â–¶  Train Loss: 0.4268  |  Val Loss: 0.4357  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 4.90e-05\n",
      "âœ… New Best! Dice 0.9895 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 51/200  â–¶  Train Loss: 0.4278  |  Val Loss: 0.4351  |  Dice: 0.9897  |  IoU: 0.9797  |  LR: 4.90e-05\n",
      "âœ… New Best! Dice 0.9897 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 52/200  â–¶  Train Loss: 0.4267  |  Val Loss: 0.4351  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 4.90e-05\n",
      "Epoch 53/200  â–¶  Train Loss: 0.4263  |  Val Loss: 0.4350  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 4.90e-05\n",
      "Epoch 54/200  â–¶  Train Loss: 0.4258  |  Val Loss: 0.4343  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 4.90e-05\n",
      "Epoch 55/200  â–¶  Train Loss: 0.4253  |  Val Loss: 0.4344  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 4.90e-05\n",
      "Epoch 56/200  â–¶  Train Loss: 0.4251  |  Val Loss: 0.4344  |  Dice: 0.9889  |  IoU: 0.9781  |  LR: 4.90e-05\n",
      "Epoch 57/200  â–¶  Train Loss: 0.4249  |  Val Loss: 0.4344  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 4.90e-05\n",
      "Epoch 58/200  â–¶  Train Loss: 0.4240  |  Val Loss: 0.4336  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 4.90e-05\n",
      "Epoch 59/200  â–¶  Train Loss: 0.4242  |  Val Loss: 0.4330  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 4.90e-05\n",
      "Epoch 60/200  â–¶  Train Loss: 0.4238  |  Val Loss: 0.4341  |  Dice: 0.9887  |  IoU: 0.9778  |  LR: 4.90e-05\n",
      "Epoch 61/200  â–¶  Train Loss: 0.4243  |  Val Loss: 0.4331  |  Dice: 0.9887  |  IoU: 0.9777  |  LR: 4.90e-05\n",
      "Epoch 62/200  â–¶  Train Loss: 0.4234  |  Val Loss: 0.4327  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 63/200  â–¶  Train Loss: 0.4232  |  Val Loss: 0.4327  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 3.43e-05\n",
      "Epoch 64/200  â–¶  Train Loss: 0.4229  |  Val Loss: 0.4323  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 65/200  â–¶  Train Loss: 0.4226  |  Val Loss: 0.4326  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 66/200  â–¶  Train Loss: 0.4228  |  Val Loss: 0.4327  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 3.43e-05\n",
      "Epoch 67/200  â–¶  Train Loss: 0.4225  |  Val Loss: 0.4318  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 3.43e-05\n",
      "Epoch 68/200  â–¶  Train Loss: 0.4219  |  Val Loss: 0.4320  |  Dice: 0.9898  |  IoU: 0.9799  |  LR: 3.43e-05\n",
      "âœ… New Best! Dice 0.9898 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 69/200  â–¶  Train Loss: 0.4215  |  Val Loss: 0.4322  |  Dice: 0.9892  |  IoU: 0.9787  |  LR: 3.43e-05\n",
      "Epoch 70/200  â–¶  Train Loss: 0.4217  |  Val Loss: 0.4318  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 71/200  â–¶  Train Loss: 0.4216  |  Val Loss: 0.4321  |  Dice: 0.9890  |  IoU: 0.9784  |  LR: 3.43e-05\n",
      "Epoch 72/200  â–¶  Train Loss: 0.4211  |  Val Loss: 0.4313  |  Dice: 0.9899  |  IoU: 0.9801  |  LR: 3.43e-05\n",
      "âœ… New Best! Dice 0.9899 ì €ì¥ ì™„ë£Œ\n",
      "Epoch 73/200  â–¶  Train Loss: 0.4212  |  Val Loss: 0.4312  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 3.43e-05\n",
      "Epoch 74/200  â–¶  Train Loss: 0.4211  |  Val Loss: 0.4312  |  Dice: 0.9896  |  IoU: 0.9796  |  LR: 3.43e-05\n",
      "Epoch 75/200  â–¶  Train Loss: 0.4208  |  Val Loss: 0.4311  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 2.40e-05\n",
      "Epoch 76/200  â–¶  Train Loss: 0.4207  |  Val Loss: 0.4314  |  Dice: 0.9893  |  IoU: 0.9790  |  LR: 2.40e-05\n",
      "Epoch 77/200  â–¶  Train Loss: 0.4201  |  Val Loss: 0.4311  |  Dice: 0.9889  |  IoU: 0.9782  |  LR: 2.40e-05\n",
      "Epoch 78/200  â–¶  Train Loss: 0.4207  |  Val Loss: 0.4311  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 2.40e-05\n",
      "Epoch 79/200  â–¶  Train Loss: 0.4201  |  Val Loss: 0.4309  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 2.40e-05\n",
      "Epoch 80/200  â–¶  Train Loss: 0.4202  |  Val Loss: 0.4314  |  Dice: 0.9890  |  IoU: 0.9783  |  LR: 2.40e-05\n",
      "Epoch 81/200  â–¶  Train Loss: 0.4200  |  Val Loss: 0.4310  |  Dice: 0.9896  |  IoU: 0.9795  |  LR: 2.40e-05\n",
      "Epoch 82/200  â–¶  Train Loss: 0.4208  |  Val Loss: 0.4308  |  Dice: 0.9898  |  IoU: 0.9799  |  LR: 2.40e-05\n",
      "Epoch 83/200  â–¶  Train Loss: 0.4199  |  Val Loss: 0.4304  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 2.40e-05\n",
      "Epoch 84/200  â–¶  Train Loss: 0.4201  |  Val Loss: 0.4307  |  Dice: 0.9891  |  IoU: 0.9786  |  LR: 2.40e-05\n",
      "Epoch 85/200  â–¶  Train Loss: 0.4196  |  Val Loss: 0.4311  |  Dice: 0.9887  |  IoU: 0.9778  |  LR: 2.40e-05\n",
      "Epoch 86/200  â–¶  Train Loss: 0.4191  |  Val Loss: 0.4307  |  Dice: 0.9892  |  IoU: 0.9788  |  LR: 2.40e-05\n",
      "Epoch 87/200  â–¶  Train Loss: 0.4198  |  Val Loss: 0.4307  |  Dice: 0.9889  |  IoU: 0.9780  |  LR: 2.40e-05\n",
      "Epoch 88/200  â–¶  Train Loss: 0.4194  |  Val Loss: 0.4306  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 89/200  â–¶  Train Loss: 0.4195  |  Val Loss: 0.4307  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 1.68e-05\n",
      "Epoch 90/200  â–¶  Train Loss: 0.4190  |  Val Loss: 0.4305  |  Dice: 0.9891  |  IoU: 0.9785  |  LR: 1.68e-05\n",
      "Epoch 91/200  â–¶  Train Loss: 0.4188  |  Val Loss: 0.4304  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 92/200  â–¶  Train Loss: 0.4188  |  Val Loss: 0.4302  |  Dice: 0.9894  |  IoU: 0.9791  |  LR: 1.68e-05\n",
      "Epoch 93/200  â–¶  Train Loss: 0.4189  |  Val Loss: 0.4300  |  Dice: 0.9896  |  IoU: 0.9794  |  LR: 1.68e-05\n",
      "Epoch 94/200  â–¶  Train Loss: 0.4185  |  Val Loss: 0.4302  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 1.68e-05\n",
      "Epoch 95/200  â–¶  Train Loss: 0.4181  |  Val Loss: 0.4300  |  Dice: 0.9897  |  IoU: 0.9796  |  LR: 1.68e-05\n",
      "Epoch 96/200  â–¶  Train Loss: 0.4186  |  Val Loss: 0.4302  |  Dice: 0.9893  |  IoU: 0.9790  |  LR: 1.68e-05\n",
      "Epoch 97/200  â–¶  Train Loss: 0.4183  |  Val Loss: 0.4301  |  Dice: 0.9895  |  IoU: 0.9793  |  LR: 1.68e-05\n",
      "Epoch 98/200  â–¶  Train Loss: 0.4181  |  Val Loss: 0.4298  |  Dice: 0.9898  |  IoU: 0.9798  |  LR: 1.68e-05\n",
      "Epoch 99/200  â–¶  Train Loss: 0.4180  |  Val Loss: 0.4301  |  Dice: 0.9896  |  IoU: 0.9796  |  LR: 1.68e-05\n",
      "Epoch 100/200  â–¶  Train Loss: 0.4179  |  Val Loss: 0.4299  |  Dice: 0.9894  |  IoU: 0.9792  |  LR: 1.68e-05\n",
      "Epoch 101/200  â–¶  Train Loss: 0.4176  |  Val Loss: 0.4299  |  Dice: 0.9896  |  IoU: 0.9795  |  LR: 1.18e-05\n",
      "Epoch 102/200  â–¶  Train Loss: 0.4179  |  Val Loss: 0.4301  |  Dice: 0.9893  |  IoU: 0.9788  |  LR: 1.18e-05\n",
      "\n",
      "ğŸ›‘ Early stopping at epoch 102\n",
      "\n",
      "ğŸ“¥ Best ëª¨ë¸ ë¡œë”© ì¤‘: C:/Users/USER/Desktop/Reco_Notebook\\results\\best_model\n",
      "âœ… Best ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...\n",
      "\n",
      "ğŸ—‚ï¸ STEP 4: ê¹”ë”í•œ ê²°ê³¼ ì €ì¥\n",
      "ğŸ—‚ï¸ ê¹”ë”í•œ ê²°ê³¼ ì €ì¥ ì‹œì‘...\n",
      "âœ… 1. Best Model í™•ì¸ë¨: C:/Users/USER/Desktop/Reco_Notebook\\results\\best_model\n",
      "ğŸ¨ 2. ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì €ì¥ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì‹œê°í™” ì €ì¥: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [02:08<00:00, 10.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2. ì‹œê°í™” ì™„ë£Œ: 186ê°œ ì´ë¯¸ì§€ â†’ C:/Users/USER/Desktop/Reco_Notebook\\results\\visualizations\n",
      "âœ… 3. ì„±ëŠ¥ ê²°ê³¼ ì €ì¥: C:/Users/USER/Desktop/Reco_Notebook\\results\\performance\n",
      "\n",
      "ğŸ‰ ê¹”ë”í•œ ì €ì¥ ì™„ë£Œ!\n",
      "ğŸ“ ì €ì¥ ìœ„ì¹˜: C:/Users/USER/Desktop/Reco_Notebook\\results\n",
      "ğŸ“Š êµ¬ì¡°:\n",
      "  â”œâ”€â”€ best_model/        (í•™ìŠµëœ ëª¨ë¸)\n",
      "  â”œâ”€â”€ visualizations/    (186ê°œ ì˜ˆì¸¡ ì‹œê°í™”)\n",
      "  â””â”€â”€ performance/       (ì„±ëŠ¥ ê·¸ë˜í”„ + ë¦¬í¬íŠ¸)\n",
      "\n",
      "ğŸ‰ ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\n",
      "ğŸ“ C:/Users/USER/Desktop/Reco_Notebook\\results\n",
      "ğŸ“Š ìµœì¢… ì„±ëŠ¥: Dice 0.9899, IoU 0.9801\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================================\n",
    "# ğŸš€ ì™„ì „í•œ Recycle Segmentation íŒŒì´í”„ë¼ì¸\n",
    "# ===============================================================================\n",
    "\n",
    "# PyTorch ê´€ë ¨ ì„í¬íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Transformers ê´€ë ¨ ì„í¬íŠ¸\n",
    "from transformers import AutoImageProcessor, AutoModelForSemanticSegmentation\n",
    "\n",
    "# ì´ë¯¸ì§€ ì²˜ë¦¬ ê´€ë ¨ ì„í¬íŠ¸\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# ì‹œìŠ¤í…œ ë° ìœ í‹¸ë¦¬í‹° ì„í¬íŠ¸\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "import math\n",
    "from glob import glob\n",
    "\n",
    "# ì§„í–‰ìƒí™© ë° ë°ì´í„° ì²˜ë¦¬ ê´€ë ¨ ì„í¬íŠ¸\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import albumentations as A\n",
    "from itertools import cycle\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸ“‹ STEP 0: ë°ì´í„° ì •ë¦¬ ë° ê¸°ë³¸ ì„¤ì •\n",
    "# ===============================================================================\n",
    "\n",
    "print(\"ğŸ—‚ï¸ ë°ì´í„° ì •ë¦¬ ì‹œì‘...\")\n",
    "\n",
    "# ë°ì´í„° ì •ë¦¬: train í´ë”ì—ì„œ datasets í´ë”ë¡œ ì´ë™\n",
    "base_dir = \"C:/Users/USER/Desktop/Reco_Notebook\"\n",
    "os.makedirs(os.path.join(base_dir, \"datasets\"), exist_ok=True)\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "train_imgs = glob(os.path.join(train_dir, \"*.jpg\"))\n",
    "train_masks = glob(os.path.join(train_dir, \"*.png\"))\n",
    "\n",
    "print(f\"ğŸ“ train í´ë”ì—ì„œ ì°¾ì€ ì´ë¯¸ì§€: {len(train_imgs)}ê°œ\")\n",
    "print(f\"ğŸ“ train í´ë”ì—ì„œ ì°¾ì€ ë§ˆìŠ¤í¬: {len(train_masks)}ê°œ\")\n",
    "\n",
    "# ì´ë¯¸ì§€ ë³µì‚¬\n",
    "for train_img in train_imgs:\n",
    "    image_dir = os.path.join(base_dir, \"datasets\", \"images\", os.path.basename(train_img))\n",
    "    os.makedirs(os.path.dirname(image_dir), exist_ok=True)\n",
    "    shutil.copy(train_img, image_dir)\n",
    "\n",
    "# ë§ˆìŠ¤í¬ ë³µì‚¬\n",
    "for train_mask in train_masks:\n",
    "    mask_dir = os.path.join(base_dir, \"datasets\", \"masks\", os.path.basename(train_mask))\n",
    "    os.makedirs(os.path.dirname(mask_dir), exist_ok=True)\n",
    "    shutil.copy(train_mask, mask_dir)\n",
    "\n",
    "print(f\"âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ!\")\n",
    "print(f\"   ğŸ“ ì´ë¯¸ì§€: {len(train_imgs)}ê°œ â†’ datasets/images/\")\n",
    "print(f\"   ğŸ“ ë§ˆìŠ¤í¬: {len(train_masks)}ê°œ â†’ datasets/masks/\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ì •ì˜: 7ê°œ í´ë˜ìŠ¤ (background í¬í•¨)\n",
    "class_names = [\n",
    "    \"background\", \"can\", \"glass\",\n",
    "    \"paper\", \"plastic\", \"styrofoam\", \"vinyl\"\n",
    "]\n",
    "\n",
    "# í´ë˜ìŠ¤ëª… â†” ID ë§¤í•‘\n",
    "label2id = {name: i for i, name in enumerate(class_names)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# ì‹œê°í™”ìš© ìƒ‰ìƒ (ë°°ê²½ì€ íˆ¬ëª… ì²˜ë¦¬)\n",
    "class_colors_bright = [\n",
    "    None,             # background - íˆ¬ëª… (ì›ë³¸ ì´ë¯¸ì§€ ë°°ê²½ ë³´ì„)\n",
    "    (0, 255, 255),    # can - ë°ì€ ì²­ë¡ìƒ‰ (Cyan)\n",
    "    (255, 255, 0),    # glass - ë°ì€ ë…¸ë€ìƒ‰\n",
    "    (128, 255, 0),    # paper - ì—°ë‘ìƒ‰\n",
    "    (255, 0, 0),      # plastic - ë°ì€ ë¹¨ê°„ìƒ‰\n",
    "    (0, 128, 255),    # styrofoam - ë°ì€ íŒŒë€ìƒ‰\n",
    "    (255, 0, 128)     # vinyl - ë°ì€ ë¶„í™ìƒ‰\n",
    "]\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"ğŸ”§ ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì •\n",
    "image_dir = os.path.join(base_dir, \"datasets\", \"images\")\n",
    "mask_dir = os.path.join(base_dir, \"datasets\", \"masks\")\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸ” STEP 1: ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ íŒŒì¼ ë§¤ì¹­ ë° ë°ì´í„°ì…‹\n",
    "# ===============================================================================\n",
    "\n",
    "def preprocess_datasets():\n",
    "    \"\"\"datasets í´ë”ì˜ images(.jpg)ì™€ masks(.png)ë¥¼ ë§¤ì¹­í•˜ê³  í´ë˜ìŠ¤ë³„ í”½ì…€ ìˆ˜ ê³„ì‚°\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š STEP 1: datasets í´ë” ë°ì´í„° ë§¤ì¹­ ì‹œì‘\")\n",
    "\n",
    "    def get_base_name(filename):\n",
    "        \"\"\"íŒŒì¼ëª…ì—ì„œ ìˆ«ì ê¸°ë°˜ í‚¤ ìƒì„± (ìˆ«ìë§Œ ì¶”ì¶œ)\"\"\"\n",
    "        import re\n",
    "        numbers = re.findall(r'\\d+', filename)\n",
    "        return '_'.join(numbers) if numbers else filename\n",
    "\n",
    "    def find_matching_files():\n",
    "        # ìˆ«ì ê¸°ë°˜ ë§¤ì¹­ ë°©ë²• (930ê°œ ëª¨ë‘ ì„±ê³µ!)\n",
    "        image_list = [f for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]\n",
    "        mask_list = [f for f in os.listdir(mask_dir) if f.lower().endswith('.png')]\n",
    "        \n",
    "        print(f\"ğŸ“ JPG ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜: {len(image_list)}ê°œ\")\n",
    "        print(f\"ğŸ“ PNG ë§ˆìŠ¤í¬ íŒŒì¼ ê°œìˆ˜: {len(mask_list)}ê°œ\")\n",
    "        \n",
    "        def get_numeric_key(filename):\n",
    "            \"\"\"íŒŒì¼ëª…ì—ì„œ ìˆ«ìë§Œ ì¶”ì¶œí•´ì„œ í‚¤ ìƒì„±\"\"\"\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', filename)\n",
    "            return '_'.join(numbers) if numbers else filename\n",
    "        \n",
    "        # ìˆ«ì ê¸°ë°˜ìœ¼ë¡œ ë§¤ì¹­\n",
    "        image_dict = {get_numeric_key(f): f for f in image_list}\n",
    "        mask_dict = {get_numeric_key(f): f for f in mask_list}\n",
    "        \n",
    "        matched_pairs = []\n",
    "        for base_key in image_dict:\n",
    "            if base_key in mask_dict:\n",
    "                matched_pairs.append({\n",
    "                    'base_name': base_key, \n",
    "                    'image_file': image_dict[base_key], \n",
    "                    'mask_file': mask_dict[base_key]\n",
    "                })\n",
    "        \n",
    "        # ë§¤ì¹­ ê²°ê³¼ í™•ì¸\n",
    "        image_only = set(image_dict.keys()) - set(mask_dict.keys())\n",
    "        mask_only = set(mask_dict.keys()) - set(image_dict.keys())\n",
    "        \n",
    "        if image_only:\n",
    "            print(f\"âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ ì´ë¯¸ì§€: {len(image_only)}ê°œ\")\n",
    "            if len(image_only) <= 3:\n",
    "                for key in list(image_only):\n",
    "                    print(f\"   - {image_dict[key]}\")\n",
    "        \n",
    "        if mask_only:\n",
    "            print(f\"âš ï¸ ë§¤ì¹­ë˜ì§€ ì•Šì€ ë§ˆìŠ¤í¬: {len(mask_only)}ê°œ\")\n",
    "            if len(mask_only) <= 3:\n",
    "                for key in list(mask_only):\n",
    "                    print(f\"   - {mask_dict[key]}\")\n",
    "        \n",
    "        print(f\"âœ… ìˆ«ì ê¸°ë°˜ ë§¤ì¹­ ì„±ê³µ: {len(matched_pairs)}ê°œ\")\n",
    "        return matched_pairs\n",
    "\n",
    "    final_data_list = []\n",
    "    pixel_counter = Counter()\n",
    "    matched_pairs = find_matching_files()\n",
    "\n",
    "    print(f\"ğŸ” ë§¤ì¹­ëœ ì´ë¯¸ì§€-ë§ˆìŠ¤í¬ ìŒ: {len(matched_pairs)}ê°œ\")\n",
    "\n",
    "    for pair in tqdm(matched_pairs, desc=\"ë°ì´í„° ë§¤ì¹­\"):\n",
    "        img_path = os.path.join(image_dir, pair['image_file'])\n",
    "        mask_path = os.path.join(mask_dir, pair['mask_file'])\n",
    "\n",
    "        if not os.path.exists(img_path) or not os.path.exists(mask_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mask_array = np.array(Image.open(mask_path))\n",
    "            unique_classes = np.unique(mask_array)\n",
    "            for class_id in unique_classes:\n",
    "                if class_id in label2id.values():\n",
    "                    pixel_counter[class_id] += (mask_array == class_id).sum()\n",
    "\n",
    "            final_data_list.append({\n",
    "                \"image\": img_path,\n",
    "                \"label\": mask_path,\n",
    "                \"class_ids\": unique_classes.tolist(),\n",
    "                \"base_name\": pair['base_name']\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë§ˆìŠ¤í¬ ë¡œë”© ì˜¤ë¥˜: {pair['base_name']} - {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"âœ… ìµœì¢… ë°ì´í„° ê°œìˆ˜: {len(final_data_list)}ê°œ\")\n",
    "    return final_data_list, pixel_counter\n",
    "\n",
    "def create_basic_transforms(input_size=512):\n",
    "    return A.Compose([A.Resize(input_size, input_size)])\n",
    "\n",
    "class ImprovedSegDataset(Dataset):\n",
    "    def __init__(self, items, processor, input_size=512):\n",
    "        self.items = items\n",
    "        self.processor = processor\n",
    "        self.input_size = input_size\n",
    "        self.transform = create_basic_transforms(input_size)\n",
    "        self.max_class_id = max(label2id.values())\n",
    "        self.valid_items = items\n",
    "        print(f\"ğŸ“Š ì „ì²´ ë°ì´í„°ì…‹ í¬ê¸°: {len(self.valid_items)}ê°œ\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_items)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.valid_items):\n",
    "            idx = idx % len(self.valid_items)\n",
    "\n",
    "        rec = self.valid_items[idx]\n",
    "\n",
    "        try:\n",
    "            image = cv2.imread(rec['image'])\n",
    "            if image is None:\n",
    "                raise ValueError(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {rec['image']}\")\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            mask = cv2.imread(rec['label'], cv2.IMREAD_GRAYSCALE)\n",
    "            if mask is None:\n",
    "                raise ValueError(f\"ë§ˆìŠ¤í¬ ë¡œë“œ ì‹¤íŒ¨: {rec['label']}\")\n",
    "\n",
    "            if image.shape[:2] != mask.shape[:2]:\n",
    "                h, w = min(image.shape[0], mask.shape[0]), min(image.shape[1], mask.shape[1])\n",
    "                image = cv2.resize(image, (w, h), interpolation=cv2.INTER_AREA)\n",
    "                mask = cv2.resize(mask, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "            mask = np.clip(mask, 0, self.max_class_id)\n",
    "\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    transformed = self.transform(image=image, mask=mask)\n",
    "                    image, mask = transformed['image'], transformed['mask']\n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ Transform ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "            try:\n",
    "                proc = self.processor(images=image, return_tensors=\"pt\")\n",
    "                pixel_values = proc[\"pixel_values\"].squeeze(0)\n",
    "            except Exception as e:\n",
    "                image_tensor = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
    "                pixel_values = image_tensor\n",
    "\n",
    "            labels = torch.tensor(mask, dtype=torch.long)\n",
    "\n",
    "            return {\n",
    "                \"pixel_values\": pixel_values,\n",
    "                \"labels\": labels,\n",
    "                \"filename\": os.path.basename(rec['image']),\n",
    "                \"original_image_path\": rec['image']\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {rec['image']} - {str(e)}\")\n",
    "            if idx == 0:\n",
    "                return self._get_dummy_data()\n",
    "            else:\n",
    "                return self.__getitem__(0)\n",
    "\n",
    "    def _get_dummy_data(self):\n",
    "        dummy_image = torch.zeros(3, self.input_size, self.input_size, dtype=torch.float32)\n",
    "        dummy_mask = torch.zeros(self.input_size, self.input_size, dtype=torch.long)\n",
    "        return {\n",
    "            \"pixel_values\": dummy_image,\n",
    "            \"labels\": dummy_mask,\n",
    "            \"filename\": \"dummy.jpg\",\n",
    "            \"original_image_path\": \"dummy_path\"\n",
    "        }\n",
    "\n",
    "def create_clean_dataset(items, processor, input_size=512):\n",
    "    print(f\"ğŸ” í•„í„°ë§ ì—†ëŠ” ë°ì´í„°ì…‹ ìƒì„± ì¤‘...\")\n",
    "    print(f\"ğŸ“Š ì…ë ¥ ë°ì´í„° ê°œìˆ˜: {len(items)}ê°œ\")\n",
    "    dataset = ImprovedSegDataset(items, processor, input_size)\n",
    "    print(f\"âœ… ìµœì¢… ë°ì´í„°ì…‹ í¬ê¸°: {len(dataset)}ê°œ\")\n",
    "    return dataset\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸš€ STEP 2: Loss í•¨ìˆ˜ ë° í•™ìŠµ ì‹œìŠ¤í…œ\n",
    "# ===============================================================================\n",
    "\n",
    "class CombinedBoundaryLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None, dice_weight=0.5, ce_weight=0.3, boundary_weight=0.2, smooth=1e-7):\n",
    "        super().__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        self.boundary_weight = boundary_weight\n",
    "        self.smooth = smooth\n",
    "\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('sobel_x', sobel_x)\n",
    "        self.register_buffer('sobel_y', sobel_y)\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        ce_loss = F.cross_entropy(logits, targets, weight=self.class_weights)\n",
    "\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        dice_losses = []\n",
    "        num_classes = logits.shape[1]\n",
    "        for cls in range(1, num_classes):\n",
    "            t_cls = (targets == cls).float()\n",
    "            p_cls = probs[:, cls]\n",
    "            inter = (p_cls * t_cls).sum(dim=[1,2])\n",
    "            union = p_cls.sum(dim=[1,2]) + t_cls.sum(dim=[1,2])\n",
    "            dice_score = ((2 * inter + self.smooth) / (union + self.smooth))\n",
    "            dice_losses.append(1 - dice_score)\n",
    "\n",
    "        if dice_losses:\n",
    "            dice_loss = torch.stack(dice_losses, dim=1).mean()\n",
    "        else:\n",
    "            dice_loss = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        # Boundary Loss\n",
    "        pred_mask = torch.argmax(probs, dim=1, keepdim=True).float()\n",
    "        gt_mask = targets.unsqueeze(1).float()\n",
    "\n",
    "        gx_pred = F.conv2d(pred_mask, self.sobel_x, padding=1)\n",
    "        gy_pred = F.conv2d(pred_mask, self.sobel_y, padding=1)\n",
    "        edge_pred = torch.sqrt(gx_pred ** 2 + gy_pred ** 2 + 1e-8)\n",
    "\n",
    "        gx_gt = F.conv2d(gt_mask, self.sobel_x, padding=1)\n",
    "        gy_gt = F.conv2d(gt_mask, self.sobel_y, padding=1)\n",
    "        edge_gt = torch.sqrt(gx_gt ** 2 + gy_gt ** 2 + 1e-8)\n",
    "\n",
    "        edge_mask = (edge_gt > 0.1).float()\n",
    "        if edge_mask.sum() > 0:\n",
    "            boundary_loss = F.l1_loss(edge_pred * edge_mask, edge_gt * edge_mask)\n",
    "        else:\n",
    "            boundary_loss = torch.tensor(0.0, device=logits.device)\n",
    "\n",
    "        total_loss = (\n",
    "            self.ce_weight * ce_loss +\n",
    "            self.dice_weight * dice_loss +\n",
    "            self.boundary_weight * boundary_loss\n",
    "        )\n",
    "        return total_loss\n",
    "\n",
    "def calculate_improved_weights(data_list, device='cuda'):\n",
    "    \"\"\"í´ë˜ìŠ¤ ê°œìˆ˜ ë§ì¶˜ ê°œì„ ëœ ê°€ì¤‘ì¹˜ ê³„ì‚°\"\"\"\n",
    "    pixel_counter = Counter()\n",
    "\n",
    "    for rec in data_list:\n",
    "        try:\n",
    "            mask = np.array(Image.open(rec[\"label\"]).convert(\"L\"))\n",
    "            unique, counts = np.unique(mask, return_counts=True)\n",
    "            for cls_id, count in zip(unique, counts):\n",
    "                if 0 <= cls_id <= 6:\n",
    "                    pixel_counter[cls_id] += count\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    fg_pixels = {k: v for k, v in pixel_counter.items() if k > 0}\n",
    "    total_fg = sum(fg_pixels.values())\n",
    "\n",
    "    weights = np.ones(7)\n",
    "    weights[0] = 0.05\n",
    "\n",
    "    for cls_id in range(1, 7):\n",
    "        if cls_id in fg_pixels:\n",
    "            freq = fg_pixels[cls_id] / total_fg\n",
    "            weights[cls_id] = np.sqrt(1.0 / (freq + 1e-6))\n",
    "\n",
    "    weights[1:] = weights[1:] / weights[1:].sum() * 6\n",
    "\n",
    "    print(f\"\\nğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:\")\n",
    "    for i, w in enumerate(weights):\n",
    "        class_name = id2label.get(i, f\"class_{i}\")\n",
    "        print(f\"  {class_name}: {w:.3f}\")\n",
    "\n",
    "    return torch.tensor(weights, dtype=torch.float32, device=device)\n",
    "\n",
    "def remove_tiny_noise_with_confidence(pred_mask, single_probs, min_area_ratio=0.003, conf_thresh=0.3, adaptive_thresh=True):\n",
    "    \"\"\"ë…¸ì´ì¦ˆ ì œê±° í•¨ìˆ˜\"\"\"\n",
    "    H, W = pred_mask.shape\n",
    "    total_pixels = H * W\n",
    "    filtered_mask = np.zeros_like(pred_mask)\n",
    "\n",
    "    for cls_id in np.unique(pred_mask):\n",
    "        if cls_id == 0:\n",
    "            continue\n",
    "\n",
    "        class_mask = (pred_mask == cls_id).astype(np.uint8)\n",
    "        num_labels, labels = cv2.connectedComponents(class_mask)\n",
    "\n",
    "        if adaptive_thresh:\n",
    "            class_confidences = single_probs[cls_id][class_mask == 1]\n",
    "            if len(class_confidences) > 0:\n",
    "                adaptive_conf_thresh = max(conf_thresh, np.percentile(class_confidences, 75))\n",
    "            else:\n",
    "                adaptive_conf_thresh = conf_thresh\n",
    "        else:\n",
    "            adaptive_conf_thresh = conf_thresh\n",
    "\n",
    "        for label_id in range(1, num_labels):\n",
    "            component_mask = (labels == label_id)\n",
    "            area = component_mask.sum()\n",
    "            area_ratio = area / total_pixels\n",
    "\n",
    "            if area_ratio >= min_area_ratio:\n",
    "                filtered_mask[component_mask] = cls_id\n",
    "            else:\n",
    "                comp_confidences = single_probs[cls_id][component_mask]\n",
    "                max_conf = comp_confidences.max() if comp_confidences.size > 0 else 0.0\n",
    "\n",
    "                if max_conf >= adaptive_conf_thresh:\n",
    "                    filtered_mask[component_mask] = cls_id\n",
    "\n",
    "    return filtered_mask\n",
    "\n",
    "def refine_mask_morphology(mask, kernel_size=5):\n",
    "    \"\"\"í˜•íƒœí•™ì  ì—°ì‚°\"\"\"\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))\n",
    "    opened = cv2.morphologyEx(mask.astype(np.uint8), cv2.MORPH_OPEN, kernel)\n",
    "    closed = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)\n",
    "    return closed\n",
    "\n",
    "def gentle_predict(batch, model, input_size=512, num_classes=10, confidence_threshold=None, use_multiscale=False, use_tta=False):\n",
    "    \"\"\"ì˜ˆì¸¡ í•¨ìˆ˜\"\"\"\n",
    "    imgs = batch[\"pixel_values\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        if use_tta:\n",
    "            tta_preds = []\n",
    "            \n",
    "            # ì›ë³¸\n",
    "            outputs = model(pixel_values=imgs)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            tta_preds.append(F.softmax(logits, dim=1))\n",
    "\n",
    "            # ì¢Œìš° ë°˜ì „\n",
    "            imgs_h_flipped = torch.flip(imgs, dims=[3])\n",
    "            outputs = model(pixel_values=imgs_h_flipped)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            logits_h_flipped_back = torch.flip(logits, dims=[3])\n",
    "            tta_preds.append(F.softmax(logits_h_flipped_back, dim=1))\n",
    "\n",
    "            probs = torch.stack(tta_preds).mean(dim=0)\n",
    "        else:\n",
    "            outputs = model(pixel_values=imgs)\n",
    "            logits = outputs.logits\n",
    "            if logits.shape[-2:] != (input_size, input_size):\n",
    "                logits = F.interpolate(logits, size=(input_size, input_size), mode=\"bilinear\", align_corners=False)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "        filtered_pred_list = []\n",
    "        for i in range(probs.shape[0]):\n",
    "            single_probs = probs[i].cpu().numpy()\n",
    "            pred_mask = np.argmax(single_probs, axis=0)\n",
    "\n",
    "            filtered1 = remove_tiny_noise_with_confidence(\n",
    "                pred_mask, single_probs, min_area_ratio=0.003, conf_thresh=0.3, adaptive_thresh=True\n",
    "            )\n",
    "            filtered2 = refine_mask_morphology(filtered1, kernel_size=5)\n",
    "            \n",
    "            filtered_pred_list.append(torch.tensor(filtered2, device=device))\n",
    "\n",
    "        pred = torch.stack(filtered_pred_list)\n",
    "\n",
    "    return probs, pred\n",
    "\n",
    "def improved_training(model, train_loader, val_loader, processor, class_weights_tensor,\n",
    "                     max_epochs=400, patience=40, device='cuda',\n",
    "                     use_enhanced_loss=False, use_advanced_scheduler=False):\n",
    "    \"\"\"í•™ìŠµ í•¨ìˆ˜\"\"\"\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "\n",
    "    model = model.to(device)\n",
    "    scaler = GradScaler()\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4, eps=1e-8)\n",
    "\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.7, patience=12,\n",
    "                                  threshold=0.005, min_lr=1e-6, verbose=True)\n",
    "\n",
    "    criterion = CombinedBoundaryLoss(\n",
    "        class_weights=class_weights_tensor,\n",
    "        dice_weight=0.5,\n",
    "        ce_weight=0.3,\n",
    "        boundary_weight=0.2\n",
    "    ).to(device)\n",
    "\n",
    "    history = {'train_loss': [], 'val_loss': [], 'dice_scores': [], 'iou_scores': [], 'learning_rates': []}\n",
    "    best_dice = 0.0\n",
    "    early_stop_counter = 0\n",
    "    best_model_path = os.path.join(base_dir, \"results\", \"best_model\")\n",
    "\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for batch in train_loader:\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            masks = batch[\"labels\"].to(device)\n",
    "            masks = torch.clamp(masks, 0, 9)\n",
    "            masks = F.interpolate(\n",
    "                masks.unsqueeze(1).float(),\n",
    "                size=(512, 512),\n",
    "                mode='nearest'\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(pixel_values=imgs)\n",
    "                logits = outputs.logits\n",
    "                logits = F.interpolate(logits, size=(512, 512), mode='bilinear')\n",
    "                loss = criterion(logits, masks)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Validation\n",
    "        val_dice, val_iou = evaluate_model_fairly(model, val_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                imgs = batch[\"pixel_values\"].to(device)\n",
    "                masks = batch[\"labels\"].to(device)\n",
    "                masks = torch.clamp(masks, 0, 9)\n",
    "                masks = F.interpolate(\n",
    "                    masks.unsqueeze(1).float(),\n",
    "                    size=(512, 512),\n",
    "                    mode='nearest'\n",
    "                ).squeeze(1).long()\n",
    "\n",
    "                with autocast():\n",
    "                    outputs = model(pixel_values=imgs)\n",
    "                    logits = outputs.logits\n",
    "                    logits = F.interpolate(logits, size=(512, 512), mode='bilinear')\n",
    "                    loss = criterion(logits, masks)\n",
    "                val_losses.append(loss.item())\n",
    "\n",
    "        avg_val_loss = np.mean(val_losses) if val_losses else float('inf')\n",
    "\n",
    "        scheduler.step(val_dice)\n",
    "\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['dice_scores'].append(val_dice)\n",
    "        history['iou_scores'].append(val_iou)\n",
    "        history['learning_rates'].append(current_lr)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{max_epochs}  â–¶  Train Loss: {avg_train_loss:.4f}  |  Val Loss: {avg_val_loss:.4f}  |  Dice: {val_dice:.4f}  |  IoU: {val_iou:.4f}  |  LR: {current_lr:.2e}\")\n",
    "\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            try:\n",
    "                os.makedirs(best_model_path, exist_ok=True)\n",
    "                model.eval()\n",
    "                model.save_pretrained(best_model_path, safe_serialization=False)\n",
    "                processor.save_pretrained(best_model_path)\n",
    "                print(f\"âœ… New Best! Dice {val_dice:.4f} ì €ì¥ ì™„ë£Œ\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "            early_stop_counter = 0\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"\\nğŸ›‘ Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    return history, best_model_path\n",
    "\n",
    "def evaluate_model_fairly(model, val_loader, use_strict=False):\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€\"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            _, preds = gentle_predict(batch, model, 512, 10)\n",
    "\n",
    "            targets = batch[\"labels\"].to(device)\n",
    "            targets = F.interpolate(\n",
    "                targets.unsqueeze(1).float(),\n",
    "                size=(512, 512),\n",
    "                mode=\"nearest\"\n",
    "            ).squeeze(1).long()\n",
    "\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(targets.cpu().numpy())\n",
    "\n",
    "    if all_preds and all_targets:\n",
    "        pred_flat = np.concatenate([p.flatten() for p in all_preds])\n",
    "        target_flat = np.concatenate([t.flatten() for t in all_targets])\n",
    "        dice, iou, _ = calculate_advanced_metrics(pred_flat, target_flat, 10)\n",
    "        return dice, iou\n",
    "\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def calculate_advanced_metrics(pred, target, num_classes):\n",
    "    \"\"\"ë©”íŠ¸ë¦­ ê³„ì‚°\"\"\"\n",
    "    pred = np.array(pred).flatten()\n",
    "    target = np.array(target).flatten()\n",
    "\n",
    "    valid_mask = target != 0\n",
    "    pred_valid = pred[valid_mask]\n",
    "    target_valid = target[valid_mask]\n",
    "\n",
    "    if len(target_valid) == 0:\n",
    "        return 0.0, 0.0, np.zeros(num_classes)\n",
    "\n",
    "    dice_scores = []\n",
    "    iou_scores = []\n",
    "    precision_scores = np.zeros(num_classes)\n",
    "\n",
    "    for cls in range(1, num_classes):\n",
    "        pred_cls = (pred_valid == cls)\n",
    "        target_cls = (target_valid == cls)\n",
    "\n",
    "        if target_cls.sum() == 0:\n",
    "            continue\n",
    "\n",
    "        intersection = (pred_cls & target_cls).sum()\n",
    "        union = (pred_cls | target_cls).sum()\n",
    "\n",
    "        if union > 0:\n",
    "            iou = intersection / union\n",
    "            dice = (2 * intersection) / (pred_cls.sum() + target_cls.sum())\n",
    "            iou_scores.append(iou)\n",
    "            dice_scores.append(dice)\n",
    "\n",
    "        if pred_cls.sum() > 0:\n",
    "            precision_scores[cls] = intersection / pred_cls.sum()\n",
    "\n",
    "    return (np.mean(dice_scores) if dice_scores else 0.0,\n",
    "            np.mean(iou_scores) if iou_scores else 0.0,\n",
    "            precision_scores)\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸ¨ STEP 3: ì‹œê°í™” í•¨ìˆ˜ë“¤\n",
    "# ===============================================================================\n",
    "\n",
    "def mask_to_color_rgb(mask):\n",
    "    \"\"\"ë§ˆìŠ¤í¬ë¥¼ RGB ì»¬ëŸ¬ ì´ë¯¸ì§€ë¡œ ë³€í™˜\"\"\"\n",
    "    h, w = mask.shape\n",
    "    color_mask = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                color_mask[class_mask] = color\n",
    "    \n",
    "    return color_mask\n",
    "\n",
    "def add_readable_center_labels(image, mask, class_names, label_scale=0.6):\n",
    "    \"\"\"ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ì¤‘ì‹¬ì— ì½ê¸° ì‰¬ìš´ ë¼ë²¨ ì¶”ê°€\"\"\"\n",
    "    labeled_image = image.copy()\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        class_mask = (mask == class_id)\n",
    "        if class_mask.any():\n",
    "            coords = np.where(class_mask)\n",
    "            center_y = int(np.mean(coords[0]))\n",
    "            center_x = int(np.mean(coords[1]))\n",
    "            \n",
    "            label_text = class_names[class_id]\n",
    "            \n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            font_scale = label_scale\n",
    "            thickness = 2\n",
    "            \n",
    "            (text_w, text_h), baseline = cv2.getTextSize(label_text, font, font_scale, thickness)\n",
    "            \n",
    "            box_x1 = max(0, center_x - text_w // 2 - 5)\n",
    "            box_y1 = max(0, center_y - text_h // 2 - 5)\n",
    "            box_x2 = min(image.shape[1], center_x + text_w // 2 + 5)\n",
    "            box_y2 = min(image.shape[0], center_y + text_h // 2 + 5)\n",
    "            \n",
    "            cv2.rectangle(labeled_image, (box_x1, box_y1), (box_x2, box_y2), (0, 0, 0), -1)\n",
    "            \n",
    "            text_x = center_x - text_w // 2\n",
    "            text_y = center_y + text_h // 2\n",
    "            cv2.putText(labeled_image, label_text, (text_x, text_y), font, font_scale, (255, 255, 255), thickness)\n",
    "    \n",
    "    return labeled_image\n",
    "\n",
    "def visualize_with_transparent_background(image, mask, alpha=0.7):\n",
    "    \"\"\"ë°°ê²½ì€ íˆ¬ëª…í•˜ê²Œ, ê°ì²´ë“¤ë§Œ ìƒ‰ì¹ í•´ì„œ ì˜¤ë²„ë ˆì´\"\"\"\n",
    "    result = image.copy()\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                color_overlay = np.full_like(image[class_mask], color)\n",
    "                result[class_mask] = cv2.addWeighted(\n",
    "                    image[class_mask], 1-alpha,\n",
    "                    color_overlay, alpha,\n",
    "                    0\n",
    "                )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_pure_mask_visualization(mask):\n",
    "    \"\"\"ìˆœìˆ˜ ë§ˆìŠ¤í¬ ì‹œê°í™” (ë°°ê²½ ì™„ì „ íˆ¬ëª…)\"\"\"\n",
    "    h, w = mask.shape\n",
    "    rgba_image = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "    \n",
    "    for class_id in range(1, len(class_names)):\n",
    "        if class_id < len(class_colors_bright) and class_colors_bright[class_id] is not None:\n",
    "            class_mask = (mask == class_id)\n",
    "            if class_mask.any():\n",
    "                color = class_colors_bright[class_id]\n",
    "                rgba_image[class_mask] = [color[0], color[1], color[2], 255]\n",
    "    \n",
    "    return rgba_image\n",
    "\n",
    "def save_prediction_comparison_readable(image_tensor, true_mask, pred_mask, save_path, original_image_path):\n",
    "    \"\"\"ì™„ë²½í•œ ì˜ˆì¸¡ ë¹„êµ ì €ì¥\"\"\"\n",
    "    if original_image_path and os.path.exists(original_image_path):\n",
    "        orig_img = PILImage.open(original_image_path).convert('RGB')\n",
    "        image_np = np.array(orig_img)\n",
    "\n",
    "        if image_np.shape[:2] != (512, 512):\n",
    "            image_np = cv2.resize(image_np, (512, 512))\n",
    "\n",
    "    else:\n",
    "        if torch.is_tensor(image_tensor):\n",
    "            image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "            if image_np.min() >= -3 and image_np.max() <= 3:\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image_np = image_np * std + mean\n",
    "                image_np = np.clip(image_np, 0, 1)\n",
    "\n",
    "            if image_np.max() <= 1:\n",
    "                image_np = (image_np * 255).astype(np.uint8)\n",
    "            else:\n",
    "                image_np = image_np.astype(np.uint8)\n",
    "        else:\n",
    "            image_np = image_tensor\n",
    "\n",
    "        if len(image_np.shape) == 3 and image_np.shape[2] == 3:\n",
    "            image_np = cv2.cvtColor(image_np, cv2.COLOR_BGR2RGB)\n",
    "            image_np = np.ascontiguousarray(image_np, dtype=np.uint8)\n",
    "\n",
    "    target_h, target_w = image_np.shape[:2]\n",
    "    if true_mask.shape != (target_h, target_w):\n",
    "        true_mask = cv2.resize(true_mask.astype(np.uint8), (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "    if pred_mask.shape != (target_h, target_w):\n",
    "        pred_mask = cv2.resize(pred_mask.astype(np.uint8), (target_w, target_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    true_color_rgb = mask_to_color_rgb(true_mask)\n",
    "    pred_color_rgb = mask_to_color_rgb(pred_mask)\n",
    "    \n",
    "    true_with_labels = add_readable_center_labels(true_color_rgb.copy(), true_mask, class_names, label_scale=0.7)\n",
    "    pred_with_labels = add_readable_center_labels(pred_color_rgb.copy(), pred_mask, class_names, label_scale=0.7)\n",
    "\n",
    "    transparent_overlay = visualize_with_transparent_background(image_np, pred_mask, alpha=0.6)\n",
    "    overlay_with_labels = add_readable_center_labels(transparent_overlay.copy(), pred_mask, class_names, label_scale=0.6)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    axes[0].imshow(image_np)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=12, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    axes[1].imshow(true_with_labels)\n",
    "    axes[1].set_title(\"Ground Truth\", fontsize=12, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    axes[2].imshow(pred_with_labels)\n",
    "    axes[2].set_title(\"Prediction\", fontsize=12, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    axes[3].imshow(overlay_with_labels)\n",
    "    axes[3].set_title(\"Transparent Overlay\", fontsize=12, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸ—‚ï¸ STEP 4: ê²°ê³¼ ì €ì¥ ì‹œìŠ¤í…œ\n",
    "# ===============================================================================\n",
    "\n",
    "def clean_save_all_results(model, val_loader, processor, history, final_dice, final_iou, \n",
    "                          best_model_path, save_base_dir=None):\n",
    "    \"\"\"ê¹”ë”í•œ ê²°ê³¼ ì €ì¥\"\"\"\n",
    "    if save_base_dir is None:\n",
    "        save_base_dir = os.path.join(base_dir, \"results\")\n",
    "    \n",
    "    print(\"ğŸ—‚ï¸ ê¹”ë”í•œ ê²°ê³¼ ì €ì¥ ì‹œì‘...\")\n",
    "    \n",
    "    viz_dir = os.path.join(save_base_dir, \"visualizations\")\n",
    "    perf_dir = os.path.join(save_base_dir, \"performance\")\n",
    "    \n",
    "    if os.path.exists(viz_dir):\n",
    "        shutil.rmtree(viz_dir)\n",
    "    if os.path.exists(perf_dir):\n",
    "        shutil.rmtree(perf_dir)\n",
    "    \n",
    "    os.makedirs(save_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Best Model í™•ì¸\n",
    "    model_save_dir = os.path.join(save_base_dir, \"best_model\")\n",
    "    if os.path.exists(model_save_dir):\n",
    "        files = os.listdir(model_save_dir)\n",
    "        if files:\n",
    "            print(f\"âœ… 1. Best Model í™•ì¸ë¨: {model_save_dir}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ 1. Best Model í´ë”ëŠ” ìˆì§€ë§Œ ë¹„ì–´ìˆìŒ\")\n",
    "    else:\n",
    "        print(f\"âŒ 1. Best Model í´ë” ì—†ìŒ: {model_save_dir}\")\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        model.save_pretrained(model_save_dir, safe_serialization=False)\n",
    "        processor.save_pretrained(model_save_dir)\n",
    "        print(f\"âœ… 1. Current Model ì €ì¥: {model_save_dir}\")\n",
    "    \n",
    "    # ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì €ì¥\n",
    "    os.makedirs(viz_dir, exist_ok=True)\n",
    "    print(\"ğŸ¨ 2. ëª¨ë“  ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” ì €ì¥ ì¤‘...\")\n",
    "    total_saved = save_all_prediction_visualizations(model, val_loader, viz_dir)\n",
    "    print(f\"âœ… 2. ì‹œê°í™” ì™„ë£Œ: {total_saved}ê°œ ì´ë¯¸ì§€ â†’ {viz_dir}\")\n",
    "    \n",
    "    # ì„±ëŠ¥ ê²°ê³¼ ì €ì¥\n",
    "    os.makedirs(perf_dir, exist_ok=True)\n",
    "    \n",
    "    save_training_graphs(history, os.path.join(perf_dir, \"training_history.png\"))\n",
    "    save_performance_report(history, final_dice, final_iou, os.path.join(perf_dir, \"performance_report.txt\"))\n",
    "    \n",
    "    print(f\"âœ… 3. ì„±ëŠ¥ ê²°ê³¼ ì €ì¥: {perf_dir}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ê¹”ë”í•œ ì €ì¥ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“ ì €ì¥ ìœ„ì¹˜: {save_base_dir}\")\n",
    "    print(f\"ğŸ“Š êµ¬ì¡°:\")\n",
    "    print(f\"  â”œâ”€â”€ best_model/        (í•™ìŠµëœ ëª¨ë¸)\")\n",
    "    print(f\"  â”œâ”€â”€ visualizations/    ({total_saved}ê°œ ì˜ˆì¸¡ ì‹œê°í™”)\")\n",
    "    print(f\"  â””â”€â”€ performance/       (ì„±ëŠ¥ ê·¸ë˜í”„ + ë¦¬í¬íŠ¸)\")\n",
    "    \n",
    "    return save_base_dir\n",
    "\n",
    "def save_all_prediction_visualizations(model, val_loader, save_dir):\n",
    "    \"\"\"ëª¨ë“  validation ë°ì´í„°ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ 4íŒ¨ë„ë¡œ ì‹œê°í™”í•˜ì—¬ ì €ì¥\"\"\"\n",
    "    model.eval()\n",
    "    total_saved = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"ì‹œê°í™” ì €ì¥\")):\n",
    "            imgs = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            filenames = batch[\"filename\"]\n",
    "            \n",
    "            _, preds = gentle_predict(batch, model, 512, len(class_names))\n",
    "            \n",
    "            batch_size = imgs.shape[0]\n",
    "            for i in range(batch_size):\n",
    "                img_path = batch[\"original_image_path\"][i]\n",
    "                img_np = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "                \n",
    "                gt_mask = labels[i].cpu().numpy().astype(np.uint8)\n",
    "                pred_mask = preds[i].cpu().numpy().astype(np.uint8)\n",
    "                \n",
    "                filename = f\"prediction_{batch_idx:03d}_{i:02d}_{os.path.splitext(filenames[i])[0]}.png\"\n",
    "                save_path = os.path.join(save_dir, filename)\n",
    "                \n",
    "                create_4panel_visualization(img_np, gt_mask, pred_mask, save_path)\n",
    "                total_saved += 1\n",
    "    \n",
    "    return total_saved\n",
    "\n",
    "def create_4panel_visualization(img_np, gt_mask, pred_mask, save_path):\n",
    "    \"\"\"4íŒ¨ë„ ì‹œê°í™”: ì›ë³¸ + GT + ì˜ˆì¸¡ + ì˜¤ë²„ë ˆì´\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    \n",
    "    axes[0].imshow(img_np)\n",
    "    axes[0].set_title(\"Original Image\", fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    gt_color = mask_to_color_rgb(gt_mask)\n",
    "    gt_with_labels = add_readable_center_labels(gt_color.copy(), gt_mask, class_names, label_scale=0.7)\n",
    "    axes[1].imshow(gt_with_labels)\n",
    "    axes[1].set_title(\"Ground Truth\", fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    pred_color = mask_to_color_rgb(pred_mask)\n",
    "    pred_with_labels = add_readable_center_labels(pred_color.copy(), pred_mask, class_names, label_scale=0.7)\n",
    "    axes[2].imshow(pred_with_labels)\n",
    "    axes[2].set_title(\"Prediction\", fontsize=14, fontweight='bold')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    overlay = create_overlay(img_np, pred_mask, alpha=0.4)\n",
    "    overlay_with_labels = add_readable_center_labels(overlay, pred_mask, class_names, label_scale=0.6)\n",
    "    axes[3].imshow(overlay_with_labels)\n",
    "    axes[3].set_title(\"Overlay\", fontsize=14, fontweight='bold')\n",
    "    axes[3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "def create_overlay(img_np, pred_mask, alpha=0.4):\n",
    "    \"\"\"ì›ë³¸ ì´ë¯¸ì§€ + ì˜ˆì¸¡ ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´\"\"\"\n",
    "    overlay = img_np.copy().astype(np.float32)\n",
    "    color_mask = mask_to_color_rgb(pred_mask).astype(np.float32)\n",
    "    \n",
    "    mask_area = (pred_mask > 0)\n",
    "    overlay[mask_area] = (\n",
    "        overlay[mask_area] * (1 - alpha) + \n",
    "        color_mask[mask_area] * alpha\n",
    "    )\n",
    "    \n",
    "    return overlay.astype(np.uint8)\n",
    "\n",
    "def save_training_graphs(history, save_path):\n",
    "    \"\"\"í•™ìŠµ íˆìŠ¤í† ë¦¬ ê·¸ë˜í”„ ì €ì¥\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    axes[0, 0].plot(history['train_loss'], label='Train Loss', color='blue', linewidth=2)\n",
    "    axes[0, 0].plot(history['val_loss'], label='Val Loss', color='red', linewidth=2)\n",
    "    axes[0, 0].set_title('Training & Validation Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(history['dice_scores'], label='Dice Score', color='green', linewidth=2)\n",
    "    axes[0, 1].set_title('Dice Score', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1, 0].plot(history['iou_scores'], label='IoU Score', color='orange', linewidth=2)\n",
    "    axes[1, 0].set_title('IoU Score', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('IoU Score')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    if 'learning_rates' in history:\n",
    "        axes[1, 1].plot(history['learning_rates'], label='Learning Rate', color='purple', linewidth=2)\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        axes[1, 1].set_yscale('log')\n",
    "    else:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=200, bbox_inches='tight', facecolor='white')\n",
    "    plt.close()\n",
    "\n",
    "def save_performance_report(history, final_dice, final_iou, save_path):\n",
    "    \"\"\"ì„±ëŠ¥ ë¦¬í¬íŠ¸ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥\"\"\"\n",
    "    with open(save_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"ğŸ¯ Recycle Segmentation ì„±ëŠ¥ ë¦¬í¬íŠ¸\\n\")\n",
    "        f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"ğŸ“Š í•™ìŠµ ê²°ê³¼:\\n\")\n",
    "        f.write(f\"  â€¢ ì´ ì—í¬í¬: {len(history['train_loss'])}\\n\")\n",
    "        f.write(f\"  â€¢ ìµœì¢… Train Loss: {history['train_loss'][-1]:.4f}\\n\")\n",
    "        f.write(f\"  â€¢ ìµœì¢… Val Loss: {history['val_loss'][-1]:.4f}\\n\")\n",
    "        f.write(f\"  â€¢ ìµœê³  Dice Score: {max(history['dice_scores']):.4f}\\n\")\n",
    "        f.write(f\"  â€¢ ìµœê³  IoU Score: {max(history['iou_scores']):.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"ğŸ¯ ìµœì¢… ì„±ëŠ¥:\\n\")\n",
    "        f.write(f\"  â€¢ Dice Score: {final_dice:.4f}\\n\")\n",
    "        f.write(f\"  â€¢ IoU Score: {final_iou:.4f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"ğŸ“ˆ ì„±ëŠ¥ í‰ê°€:\\n\")\n",
    "        if final_dice > 0.85:\n",
    "            f.write(\"  âœ… ìš°ìˆ˜í•œ ì„±ëŠ¥! ì‹¤ì œ ë°°í¬ ê°€ëŠ¥í•œ ìˆ˜ì¤€\\n\")\n",
    "        elif final_dice > 0.7:\n",
    "            f.write(\"  ğŸŸ¢ ì¢‹ì€ ì„±ëŠ¥! ì‹¤ìš©ì ìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥\\n\")\n",
    "        elif final_dice > 0.5:\n",
    "            f.write(\"  ğŸŸ¡ ë³´í†µ ì„±ëŠ¥. ì¶”ê°€ ê°œì„ ìœ¼ë¡œ í–¥ìƒ ê°€ëŠ¥\\n\")\n",
    "        else:\n",
    "            f.write(\"  ğŸ”´ ì„±ëŠ¥ ë¶€ì¡±. ì¶”ê°€ íŠœë‹ í•„ìš”\\n\")\n",
    "\n",
    "# ===============================================================================\n",
    "# ğŸš€ STEP 5: ë©”ì¸ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# ===============================================================================\n",
    "\n",
    "def calculate_class_weights_from_pixel_counter(pixel_counter):\n",
    "    \"\"\"í”½ì…€ ì¹´ìš´í„°ë¡œë¶€í„° í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\"\"\"\n",
    "    print(\"\\nğŸ“Š í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì¤‘...\")\n",
    "    \n",
    "    total_pixels = sum(pixel_counter.values())\n",
    "    \n",
    "    class_weights = []\n",
    "    for class_id in range(len(class_names)):\n",
    "        if class_id in pixel_counter and pixel_counter[class_id] > 0:\n",
    "            weight = total_pixels / (len(class_names) * pixel_counter[class_id])\n",
    "        else:\n",
    "            weight = 1.0\n",
    "        class_weights.append(weight)\n",
    "    \n",
    "    max_weight = max(class_weights)\n",
    "    if max_weight > 10:\n",
    "        class_weights = [w / max_weight * 10 for w in class_weights]\n",
    "    \n",
    "    class_weights_tensor = torch.FloatTensor(class_weights)\n",
    "    \n",
    "    print(\"ğŸ¯ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜:\")\n",
    "    for i, (class_name, weight) in enumerate(zip(class_names, class_weights)):\n",
    "        pixel_count = pixel_counter.get(i, 0)\n",
    "        print(f\"   {class_name}: {weight:.3f} (í”½ì…€ ìˆ˜: {pixel_count:,})\")\n",
    "    \n",
    "    return class_weights_tensor\n",
    "\n",
    "def run_clean_pipeline():\n",
    "    \"\"\"ì™„ì „í•œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\"\"\"\n",
    "    print(\"ğŸš€ ê¹”ë”í•œ Recycle Segmentation íŒŒì´í”„ë¼ì¸ ì‹œì‘!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    try:\n",
    "        # STEP 1: ë°ì´í„° ì „ì²˜ë¦¬\n",
    "        print(\"\\nğŸ“Š STEP 1: ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘\")\n",
    "        final_data_list, pixel_counter = preprocess_datasets()\n",
    "\n",
    "        if len(final_data_list) == 0:\n",
    "            print(\"âŒ ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "            return\n",
    "\n",
    "        print(f\"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ: {len(final_data_list)}ê°œ ë°ì´í„°\")\n",
    "\n",
    "        # STEP 2: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        print(\"\\nğŸ”§ STEP 2: í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\")\n",
    "        \n",
    "        class_weights_tensor = calculate_class_weights_from_pixel_counter(pixel_counter).to(device)\n",
    "        print(f\"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ\")\n",
    "\n",
    "        # ëª¨ë¸ ë¡œë”©\n",
    "        print(\"\\nğŸ¤– ëª¨ë¸ ë° í”„ë¡œì„¸ì„œ ë¡œë”© ì¤‘...\")\n",
    "        processor = AutoImageProcessor.from_pretrained(\"apple/deeplabv3-mobilevit-small\", use_fast=True)\n",
    "        model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "            \"apple/deeplabv3-mobilevit-small\",\n",
    "            num_labels=len(class_names),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "            ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        print(\"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ\")\n",
    "\n",
    "        # Train/Val ë¶„í• \n",
    "        print(\"\\nğŸ“Š Train/Val ë°ì´í„° ë¶„í•  ì¤‘...\")\n",
    "        random.seed(42)\n",
    "        random.shuffle(final_data_list)\n",
    "        \n",
    "        split_idx = int(len(final_data_list) * 0.8)\n",
    "        train_list = final_data_list[:split_idx]\n",
    "        val_list = final_data_list[split_idx:]\n",
    "\n",
    "        print(f\"ğŸ“Š ë°ì´í„° ë¶„í•  ì™„ë£Œ: Train {len(train_list)}ê°œ, Val {len(val_list)}ê°œ\")\n",
    "\n",
    "        # ë°ì´í„°ì…‹ ìƒì„±\n",
    "        train_ds = create_clean_dataset(train_list, processor, input_size=512)\n",
    "        val_ds = create_clean_dataset(val_list, processor, input_size=512)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "        print(f\"âœ… DataLoader ìƒì„± ì™„ë£Œ: Train batches {len(train_loader)}, Val batches {len(val_loader)}\")\n",
    "\n",
    "        # STEP 3: ëª¨ë¸ í•™ìŠµ\n",
    "        print(\"\\nğŸš€ STEP 3: ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "        history, best_model_path = improved_training(\n",
    "            model, train_loader, val_loader, processor, class_weights_tensor,\n",
    "            max_epochs=200, patience=30, device=device\n",
    "        )\n",
    "\n",
    "        # Best ëª¨ë¸ ë¡œë”©\n",
    "        if best_model_path and os.path.exists(best_model_path):\n",
    "            print(f\"\\nğŸ“¥ Best ëª¨ë¸ ë¡œë”© ì¤‘: {best_model_path}\")\n",
    "            try:\n",
    "                model = AutoModelForSemanticSegmentation.from_pretrained(\n",
    "                    best_model_path, local_files_only=True\n",
    "                ).to(device)\n",
    "                processor = AutoImageProcessor.from_pretrained(best_model_path)\n",
    "                print(\"âœ… Best ëª¨ë¸ ë¡œë”© ì™„ë£Œ!\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Best ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "        # ìµœì¢… ì„±ëŠ¥ í‰ê°€\n",
    "        print(\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ í‰ê°€ ì¤‘...\")\n",
    "        model.eval()\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                _, pred = gentle_predict(batch, model, 512, len(class_names))\n",
    "                all_preds.append(pred.cpu().numpy())\n",
    "                all_targets.append(batch[\"labels\"].cpu().numpy())\n",
    "        \n",
    "        pred_flat = np.concatenate([p.flatten() for p in all_preds])\n",
    "        target_flat = np.concatenate([t.flatten() for t in all_targets])\n",
    "        final_dice, final_iou, _ = calculate_advanced_metrics(pred_flat, target_flat, len(class_names))\n",
    "\n",
    "        # STEP 4: ê²°ê³¼ ì €ì¥\n",
    "        print(\"\\nğŸ—‚ï¸ STEP 4: ê¹”ë”í•œ ê²°ê³¼ ì €ì¥\")\n",
    "        save_dir = clean_save_all_results(\n",
    "            model, val_loader, processor, history, \n",
    "            final_dice, final_iou, best_model_path\n",
    "        )\n",
    "\n",
    "        print(f\"\\nğŸ‰ ì™„ë£Œ! ëª¨ë“  ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "        print(f\"ğŸ“ {save_dir}\")\n",
    "        print(f\"ğŸ“Š ìµœì¢… ì„±ëŠ¥: Dice {final_dice:.4f}, IoU {final_iou:.4f}\")\n",
    "\n",
    "        return save_dir\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    run_clean_pipeline()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
